---
phase: 11-foraging-specialization
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - bin/lib/telemetry.js
  - .aether/data/telemetry.json
autonomous: true

must_haves:
  truths:
    - "Telemetry records every spawn with model, caste, task, and routing source"
    - "Telemetry tracks success/failure rates per model-caste combination"
    - "Telemetry file rotates at 1000 routing decisions to prevent unbounded growth"
    - "Telemetry uses atomic writes (temp file + rename) for data integrity"
  artifacts:
    - path: "bin/lib/telemetry.js"
      provides: "Telemetry recording and querying functions"
      exports: ["recordSpawnTelemetry", "updateSpawnOutcome", "getTelemetrySummary", "getModelPerformance"]
    - path: ".aether/data/telemetry.json"
      provides: "Telemetry data storage"
      schema: "{ version, last_updated, models: {}, routing_decisions: [] }"
  key_links:
    - from: "spawn-logger.js"
      to: "telemetry.js"
      via: "recordSpawnTelemetry call"
      pattern: "recordSpawnTelemetry(repoPath, spawnInfo)"
---

<objective>
Create telemetry system for tracking model performance and routing decisions.

Purpose: Enable data-driven model selection by tracking success rates per model/caste, fulfilling MOD-07 requirement.
Output: New telemetry.js module with recording, querying, and rotation capabilities.
</objective>

<execution_context>
@~/.claude/cosmic-dev-system/workflows/execute-plan.md
@~/.claude/cosmic-dev-system/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/phases/11-foraging-specialization/11-RESEARCH.md
@/Users/callumcowie/repos/Aether/bin/lib/spawn-logger.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create telemetry.js module with recording functions</name>
  <files>bin/lib/telemetry.js</files>
  <action>
Create a new module `bin/lib/telemetry.js` with the following functions:

1. **recordSpawnTelemetry(repoPath, spawnInfo)**
   - Location: `.aether/data/telemetry.json`
   - Schema for spawnInfo: { task, caste, model, source, timestamp? }
   - Load existing telemetry or create new with version "1.0"
   - Update model stats in telemetry.models[model]:
     - total_spawns (increment)
     - by_caste[caste] = { spawns, success, failures, blocked }
   - Append to routing_decisions array:
     - { timestamp, task, caste, selected_model, source }
   - Rotate routing_decisions if length > 1000 (keep last 1000)
   - Atomic write: write to temp file, then rename
   - Returns { success: true, decision_id }

2. **updateSpawnOutcome(repoPath, spawnId, outcome)**
   - outcome: 'completed' | 'failed' | 'blocked'
   - Find spawn in routing_decisions by timestamp/task match
   - Update model stats counters:
     - successful_completions, failed_completions, blocked
     - Update by_caste counters
   - Atomic write

3. **loadTelemetry(repoPath)**
   - Internal helper to load and validate telemetry.json
   - Returns parsed data or default structure if missing/invalid

4. **saveTelemetry(repoPath, data)**
   - Internal helper for atomic writes
   - Write to telemetry.json.tmp, then rename

Use the same patterns as spawn-logger.js for file paths and atomic operations.
  </action>
  <verify>ls -la bin/lib/telemetry.js && node -e "const t = require('./bin/lib/telemetry'); console.log('Exports:', Object.keys(t))"</verify>
  <done>telemetry.js module exists with recordSpawnTelemetry, updateSpawnOutcome, loadTelemetry, and saveTelemetry functions</done>
</task>

<task type="auto">
  <name>Task 2: Add telemetry querying functions</name>
  <files>bin/lib/telemetry.js</files>
  <action>
Add querying functions to telemetry.js:

1. **getTelemetrySummary(repoPath)**
   - Returns overall summary:
     ```javascript
     {
       total_spawns: N,
       total_models: N,
       models: {
         "kimi-k2.5": { total_spawns, success_rate, by_caste: {} },
         "glm-5": { ... }
       },
       recent_decisions: [] // last 10 routing decisions
     }
     ```
   - Calculate success_rate as successful_completions / total_spawns

2. **getModelPerformance(repoPath, model)**
   - Returns detailed performance for a specific model:
     ```javascript
     {
       model: "kimi-k2.5",
       total_spawns: N,
       successful_completions: N,
       failed_completions: N,
       blocked: N,
       success_rate: 0.95,
       by_caste: {
         "builder": { spawns: N, success: N, failures: N },
         "watcher": { ... }
       }
     }
     ```

3. **getRoutingStats(repoPath, options)**
   - options: { days?: number, caste?: string }
   - Returns routing decision statistics filtered by time/caste

Export all functions from the module.
  </action>
  <verify>node -e "const t = require('./bin/lib/telemetry'); console.log('Query exports:', Object.keys(t).filter(k => k.includes('get') || k.includes('Summary')))"</verify>
  <done>Query functions getTelemetrySummary, getModelPerformance, and getRoutingStats are implemented and exported</done>
</task>

<task type="auto">
  <name>Task 3: Integrate telemetry with spawn-logger</name>
  <files>bin/lib/spawn-logger.js</files>
  <action>
Modify spawn-logger.js to call telemetry recording:

1. Import the telemetry module at the top:
   ```javascript
   const { recordSpawnTelemetry } = require('./telemetry');
   ```

2. In the `logSpawn` function, after appending to spawn-tree.txt:
   - Call recordSpawnTelemetry with the spawn info
   - Pass: repoPath, { task, caste, model, source: 'caste-default' }
   - Note: source should come from caller in future, use 'caste-default' for now

3. Handle telemetry errors gracefully (don't fail spawn logging if telemetry fails)

4. Update the function signature to accept an optional `source` parameter:
   ```javascript
   async function logSpawn(repoPath, { parent, caste, child, task, model, status = 'spawned', source = 'caste-default' })
   ```

This ensures every spawn is recorded in telemetry for performance tracking.
  </action>
  <verify>grep -q "require('./telemetry')" bin/lib/spawn-logger.js && grep -q "recordSpawnTelemetry" bin/lib/spawn-logger.js && echo "Integration complete"</verify>
  <done>spawn-logger.js calls recordSpawnTelemetry for every spawn event</done>
</task>

<task type="auto">
  <name>Task 4: Add unit tests for telemetry</name>
  <files>test/telemetry.test.js</files>
  <action>
Create comprehensive unit tests for telemetry.js:

1. **recordSpawnTelemetry tests:**
   - Creates telemetry.json if it doesn't exist
   - Updates existing telemetry correctly
   - Increments total_spawns for the model
   - Creates by_caste entry if new caste
   - Appends to routing_decisions
   - Rotates routing_decisions at 1000 entries
   - Uses atomic writes (temp file + rename)

2. **updateSpawnOutcome tests:**
   - Updates successful_completions counter
   - Updates failed_completions counter
   - Updates blocked counter
   - Updates by_caste counters correctly

3. **Query function tests:**
   - getTelemetrySummary returns correct structure
   - getModelPerformance returns correct stats for a model
   - getRoutingStats filters by days correctly
   - Success rate calculation is accurate

4. **Error handling tests:**
   - Handles corrupted telemetry.json gracefully
   - Handles missing directory (creates it)
   - Handles permission errors gracefully

Use temporary directories for test isolation. Mock fs where appropriate.
  </action>
  <verify>npm test -- test/telemetry.test.js 2>&1 | grep -E "(passed|failed)" | tail -1</verify>
  <done>All telemetry tests pass with >90% coverage</done>
</task>

</tasks>

<verification>
1. Run telemetry tests: npm test -- test/telemetry.test.js
2. Manual test: node -e "const t = require('./bin/lib/telemetry'); t.recordSpawnTelemetry('.', {task: 'test', caste: 'builder', model: 'kimi-k2.5', source: 'test'}); console.log(t.getTelemetrySummary('.'))"
3. Verify telemetry.json is created and has correct structure
4. Test rotation: manually add 1001 decisions and verify rotation
</verification>

<success_criteria>
- [ ] telemetry.js module exists with all required functions
- [ ] recordSpawnTelemetry creates/updates telemetry.json correctly
- [ ] updateSpawnOutcome updates counters correctly
- [ ] Query functions return accurate performance data
- [ ] Routing decisions rotate at 1000 entries
- [ ] Atomic writes prevent data corruption
- [ ] spawn-logger.js integrates telemetry recording
- [ ] Unit tests pass with >90% coverage
</success_criteria>

<output>
After completion, create `.planning/phases/11-foraging-specialization/11-02-SUMMARY.md`
</output>

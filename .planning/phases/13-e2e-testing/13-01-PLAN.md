---
phase: 13-e2e-testing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .planning/phases/13-e2e-testing/E2E-TEST-GUIDE.md
autonomous: true
user_setup: []

must_haves:
  truths:
    - "User can follow step-by-step instructions to test init workflow"
    - "User can verify autonomous spawning occurs during execute workflow"
    - "User can verify Bayesian confidence updates during spawning workflow"
    - "User can verify DAST compression during memory workflow"
    - "User can verify weighted voting and Critical veto during voting workflow"
    - "User can verify event polling, delivery, and tracking during event workflow"
  artifacts:
    - path: ".planning/phases/13-e2e-testing/E2E-TEST-GUIDE.md"
      provides: "Comprehensive manual test guide for all core workflows"
      min_lines: 500
      contains_sections:
        - "Introduction"
        - "Test Environment Setup"
        - "Workflow 1: Init"
        - "Workflow 2: Execute"
        - "Workflow 3: Spawning"
        - "Workflow 4: Memory"
        - "Workflow 5: Voting"
        - "Workflow 6: Event"
        - "Appendix A: Verification ID Mapping"
  key_links:
    - from: "E2E-TEST-GUIDE.md"
      to: ".claude/commands/ant/init.md"
      via: "Test steps reference /ant:init command"
      pattern: "/ant:init"
    - from: "E2E-TEST-GUIDE.md"
      to: ".claude/commands/ant/execute.md"
      via: "Test steps reference /ant:execute command"
      pattern: "/ant:execute"
    - from: "E2E-TEST-GUIDE.md"
      to: ".aether/utils/test-voting-system.sh"
      via: "Verification patterns mirror existing test utilities"
      pattern: "jq.*verification"
    - from: "E2E-TEST-GUIDE.md"
      to: ".aether/utils/test-event-polling-integration.sh"
      via: "Event verification patterns mirror integration tests"
      pattern: "get_events_for_subscriber"
    - from: "E2E-TEST-GUIDE.md"
      to: ".aether/utils/test-spawning-safeguards.sh"
      via: "Spawning verification patterns mirror safeguard tests"
      pattern: "spawn_tracking|circuit_breaker"
---

<objective>
Create comprehensive manual E2E test guide documenting all core Aether colony workflows with step-by-step instructions, expected outputs, and verification checks.

Purpose: Manual testing is essential for LLM-based systems due to non-deterministic behavior. Automated tests catch component bugs, but manual tests catch reasoning issues and validate that the colony behaves intelligently in real scenarios.
Output: E2E-TEST-GUIDE.md with 6 workflow sections, each containing 3 test scenarios (happy path, failure case, edge case), with traceable verification IDs (VERIF-01 through VERIF-60+).
</objective>

<execution_context>
@~/.claude/cosmic-dev-system/workflows/execute-plan.md
@~/.claude/cosmic-dev-system/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-e2e-testing/13-CONTEXT.md
@.planning/phases/13-e2e-testing/13-RESEARCH.md

@.claude/commands/ant/init.md
@.claude/commands/ant/execute.md
@.claude/commands/ant/status.md
@.claude/commands/ant/build.md

@.aether/utils/test-voting-system.sh
@.aether/utils/test-event-polling-integration.sh
@.aether/utils/test-spawning-safeguards.sh
@.aether/utils/test-bayesian-learning.sh

@aether/workers/colonizer-ant.md
@aether/workers/architect-ant.md
</context>

<tasks>

<task type="auto">
  <name>Create E2E test guide structure with introduction and setup sections</name>
  <files>.planning/phases/13-e2e-testing/E2E-TEST-GUIDE.md</files>
  <action>
Create E2E-TEST-GUIDE.md with the following structure:

1. **Introduction Section:**
   - Purpose of manual E2E testing for LLM-based systems
   - How to use this guide (step-by-step execution)
   - Verification ID explanation (VERIF-XX format for traceability)
   - What makes E2E testing different from automated tests

2. **Test Environment Setup Section:**
   - Prerequisites (git repo, bash, jq, Aether commands available)
   - Colony state backup/restore procedures (using cp commands for state files)
   - Clean slate initialization steps
   - Test isolation best practices

3. **Workflow Section Template (to be used for all 6 workflows):**
   For each workflow (Init, Execute, Spawning, Memory, Voting, Event):
   - Overview: What this workflow does and why it matters
   - Prerequisites: Required colony state before testing
   - Test 1.X: Happy Path (success case)
   - Test 1.X+1: Failure Case (error handling)
   - Test 1.X+2: Edge Case (boundary conditions)

4. **Appendix A: Verification ID Mapping:**
   - Table mapping VERIF-XX IDs to requirements (TEST-01 through TEST-06)
   - Ensures full requirement traceability

Use markdown format with:
- H1 for main sections (#)
- H2 for workflows (##)
- H3 for test cases (###)
- H4 for subsections (####)
- Code blocks with bash for commands and expected outputs
- Bullet points for verification checks

**Important:** This task only creates the structure with placeholder workflow sections. Do NOT write actual test cases yet - that comes in the next task.

Reference RESEARCH.md patterns:
- Test case template from "Code Examples > Test Case Template"
- Verification check examples from "Code Examples > Verification Check Examples"
- State backup/restore pattern from "Code Examples > State Backup/Restore Pattern"
</action>
  <verify>File exists at .planning/phases/13-e2e-testing/E2E-TEST-GUIDE.md with all major sections (Introduction, Test Environment Setup, 6 workflow placeholders, Appendix A)</verify>
  <done>Guide structure created with placeholder sections for 6 workflows</done>
</task>

<task type="auto">
  <name>Write workflow test cases (Init, Execute, Spawning)</name>
  <files>.planning/phases/13-e2e-testing/E2E-TEST-GUIDE.md</files>
  <action>
Write comprehensive test cases for the first 3 workflows (Init, Execute, Spawning).

For each workflow, write 3 test cases (happy path, failure case, edge case):

**Workflow 1: Init (Colony Initialization)**
- Test 1.1: Happy Path - Successful colony initialization with valid goal
  - Steps: Run /ant:init with valid goal
  - Expected output: Full initialization output with step progress, colony mobilized message, Worker Ants listed with emoji status indicators
  - Verification checks (VERIF-01 through VERIF-08): State file exists, goal stored, colony status INIT, phase 1, all workers ready, INIT pheromone active, session ID generated, working memory contains intention
  - State verification: Before (no state file), After (verify all fields)

- Test 1.2: Failure Case - Re-initialization attempt
  - Steps: Run /ant:init twice without resetting
  - Expected output: Error message "Colony already initialized"
  - Verification checks (VERIF-09 through VERIF-11): Second init fails, original goal preserved, state unchanged

- Test 1.3: Edge Case - Empty or invalid goal input
  - Steps: Run /ant:init with empty string or very long goal
  - Expected output: Graceful handling or validation error
  - Verification checks (VERIF-12 through VERIF-14): Input validation works, colony not partially initialized, clear error message

**Workflow 2: Execute (Phase Execution)**
- Test 2.1: Happy Path - Successful phase execution with autonomous spawning
  - Steps: Initialize colony, run /ant:execute 1, observe execution
  - Expected output: Step progress (6 steps), Worker Ant mobilization, autonomous spawning messages (Task tool invocations), phase completion
  - Verification checks (VERIF-15 through VERIF-22): Phase status changes to in_progress then completed, autonomous spawning occurs (Task tool used), Worker Ant activity indicators update, pheromones emitted, events published
  - State verification: Before (phase ready), After (phase completed, spawn tracking populated)

- Test 2.2: Failure Case - Phase execution with blocked tasks
  - Steps: Create scenario where tasks cannot complete (missing dependencies), run /ant:execute
  - Expected output: Error handling, phase status shows blocked/incomplete
  - Verification checks (VERIF-23 through VERIF-26): Errors logged, phase not marked complete, spawn budget not exhausted, colony recovers

- Test 2.3: Edge Case - Re-execute completed phase
  - Steps: Run /ant:execute on already completed phase
  - Expected output: Message "Phase X is already complete"
  - Verification checks (VERIF-27 through VERIF-29): Execution rejected, phase status unchanged, no duplicate spawns

**Workflow 3: Spawning (Autonomous Worker Spawning)**
- Test 3.1: Happy Path - Successful specialist spawn with Bayesian confidence update
  - Steps: Trigger scenario requiring specialist (e.g., database task), observe autonomous spawn
  - Expected output: Colonizer detects capability gap, uses Task tool to spawn database_specialist, spawn recorded in tracking
  - Verification checks (VERIF-30 through VERIF-37): Capability gap detected, specialist spawned (not duplicate), spawn_tracking.record_spawn() called, Bayesian confidence updated (alpha/beta params), circuit breaker not triggered, spawn depth within limit, spawn budget available, meta-learning data populated
  - State verification: Before (confidence baseline), After (confidence increased for successful spawn)

- Test 3.2: Failure Case - Circuit breaker activation after repeated failures
  - Steps: Force 3+ spawn failures for same specialist, attempt another spawn
  - Expected output: Circuit breaker blocks spawn, error message logged
  - Verification checks (VERIF-38 through VERIF-42): Circuit breaker status open, spawn rejected, failure_count >= 3, circuit_breaker.last_triggered timestamp set, spawn_tracking.spawn_blocked() returns true

- Test 3.3: Edge Case - Max spawn depth reached
  - Steps: Create spawn chain at max depth (5 levels), attempt another spawn
  - Expected output: Spawn rejected due to depth limit
  - Verification checks (VERIF-43 through VERIF-46): spawn_depth == 5, spawn rejected, depth_limit_enforced error logged, no infinite spawn loop

Use the test case template from RESEARCH.md for each test:
- Overview (brief description)
- Prerequisites (colony state, files needed)
- Test Steps (numbered 1, 2, 3... with bash commands)
- Expected Outputs (code blocks with terminal output including emojis and progress indicators)
- Verification Checks (bullet points with VERIF-XX IDs, specific jq commands or checks)
- State Verification (before/after jq commands)
- Cleanup (if needed)

Mirror verification patterns from existing test utilities:
- test-voting-system.sh: jq-based JSON field verification
- test-event-polling-integration.sh: Event delivery checks
- test-spawning-safeguards.sh: Spawn tracking and circuit breaker verification

Use actual expected outputs from command documentation:
- /ant:init: 7-step progress with [‚úì]/[‚Üí]/[ ] indicators
- /ant:execute: 6-step progress with Worker Ant mobilization
- /ant:status: Visual dashboard with emoji indicators (üü¢ ACTIVE, ‚ö™ IDLE, üî¥ ERROR, ‚è≥ PENDING)

Ensure each workflow has comprehensive coverage:
- Init workflow: State file creation, intention storage, colony status transition, Worker Ant mobilization, INIT pheromone emission, session ID generation, working memory initialization
- Execute workflow: Phase status transitions, autonomous spawning triggers, Task tool usage, Worker Ant activity updates, pheromone emission, event publishing
- Spawning workflow: Capability gap detection, specialist selection, spawn recording, Bayesian confidence updates, circuit breaker behavior, spawn depth limits, spawn budget enforcement

All verification checks must be specific and verifiable:
- Use jq commands for JSON verification
- Use file existence checks ([ -f file.json ])
- Use field value checks (jq -r '.field')
- Use count verification (jq 'length')
- Use status checks (jq '.status == "value"')
</action>
  <verify>Guide contains 3 complete workflow sections with 9 total test cases, each with Overview, Prerequisites, Test Steps, Expected Outputs, Verification Checks (VERIF-01 through VERIF-46), State Verification</verify>
  <done>Three workflow test cases (Init, Execute, Spawning) fully documented with verification checks</done>
</task>

<task type="auto">
  <name>Write workflow test cases (Memory, Voting, Event) and complete verification mapping</name>
  <files>.planning/phases/13-e2e-testing/E2E-TEST-GUIDE.md</files>
  <action>
Write comprehensive test cases for the remaining 3 workflows (Memory, Voting, Event) and complete Appendix A with verification ID mapping.

**Workflow 4: Memory (Triple-Layer Memory with DAST Compression)**
- Test 4.1: Happy Path - DAST compression triggered when working memory full
  - Steps: Fill working memory beyond capacity (10 items), observe compression to short-term memory
  - Expected output: Compression message, items moved to short-term memory, working memory count reduced
  - Verification checks (VERIF-47 through VERIF-53): working_memory.items count <= 10 after compression, short_term_memory populated, DAST compression applied (summary created, associations linked), associative_links created, memory_json working memory file updated, memory_metadata tracked, no memory loss

- Test 4.2: Failure Case - Memory overflow handling
  - Steps: Rapidly add items exceeding both working and short-term capacity
  - Expected output: Overflow handling, error or graceful degradation
  - Verification checks (VERIF-54 through VERIF-57): Memory overflow detected, error logged, colony remains stable, oldest items archived to long-term memory

- Test 4.3: Edge Case - Associative link creation during compression
  - Steps: Trigger compression with related items (same task, phase, or topic)
  - Expected output: Associative links created between related memory items
  - Verification checks (VERIF-58 through VERIF-60): associative_links array populated, links connect related items (same task_id/phase_id), association strength calculated, retrieval performance improved (same query returns related items)

**Workflow 5: Voting (Multi-Perspective Verification with Weighted Voting)**
- Test 5.1: Happy Path - Supermajority approval with weighted votes
  - Steps: Trigger verification (end of phase/task), observe 4 Watchers vote
  - Expected output: 4 Watchers (security, performance, quality, test_coverage) vote, supermajority calculated, result APPROVED or REJECTED
  - Verification checks (VERIF-61 through VERIF-68): All 4 Watchers vote, votes recorded in vote_tracking, supermajority calculated (>= 67% = APPROVED), weights applied (Critical = 2.0, Standard = 1.0), decision outcome logged, issues deduplicated (no duplicates), vote metadata recorded (timestamp, watcher), verification.last_supermajority updated

- Test 5.2: Failure Case - Critical veto blocks approval despite majority
  - Steps: 3 Watchers APPROVE, 1 Critical Watcher (security) VETOS
  - Expected output: Result REJECTED due to Critical veto
  - Verification checks (VERIF-69 through VERIF-73): Critical veto power exercised, result REJECTED despite 75% approval, security watcher veto recorded, critical_veto exercised = true, veto_reason logged

- Test 5.3: Edge Case - Weight calculation edge cases (0 watchers, abstentions)
  - Steps: Trigger verification with 0 watchers or all abstain
  - Expected output: Graceful handling, default decision or manual escalation
  - Verification checks (VERIF-74 through VERIF-77): Edge case handled, no crash, vote count = 0 or all abstain, decision logged with reason

**Workflow 6: Event (Event Polling and Delivery)**
- Test 6.1: Happy Path - Event polling retrieves events, delivery prevents reprocessing
  - Steps: Publish events, Worker Ant polls via get_events_for_subscriber(), marks delivered via mark_events_delivered(), poll again
  - Expected output: First poll returns events, second poll returns empty (already delivered)
  - Verification checks (VERIF-78 through VERIF-85): get_events_for_subscriber() returns matching events (topic filter works), events contain subscriber_id, topic, timestamp, data fields, mark_events_delivered() adds subscriber to delivered_to array, second poll returns no events (delivery tracking works), caste-specific subscriptions work (colonizer gets phase_complete, not task_started), event logging records poll, delivery_tracking updated

- Test 6.2: Failure Case - Event delivery failure (corrupted event data)
  - Steps: Publish event with invalid JSON, Worker Ant attempts to process
  - Expected output: Error logged, event not processed, colony continues
  - Verification checks (VERIF-86 through VERIF-89): Invalid event detected, error logged in event tracking, Worker Ant continues (doesn't crash), event marked as failed if applicable

- Test 6.3: Edge Case - Caste-specific filtering (different castes receive different events)
  - Steps: Publish multiple events (phase_complete, task_started, error), have colonizer and watcher poll separately
  - Expected output: Colonizer receives phase_complete + error, Watcher receives task_completed + task_failed + error
  - Verification checks (VERIF-90 through VERIF-94): Colonizer subscriptions: phase_complete, spawn_request, error, Watcher subscriptions: task_completed, task_failed, phase_complete, error, Topic filtering works (no cross-over), Event delivery is subscriber-specific, Error topic received by all castes, Subscription criteria applied correctly

**Appendix A: Verification ID Mapping**
Create comprehensive table mapping all VERIF-XX IDs to requirements:

| Verification ID | Requirement | Description |
|----------------|-------------|-------------|
| VERIF-01 | TEST-01 | Init workflow - state file creation |
| VERIF-02 | TEST-01 | Init workflow - intention storage |
| VERIF-03 | TEST-01 | Init workflow - colony status transition |
| VERIF-04 | TEST-01 | Init workflow - current phase set |
| VERIF-05 | TEST-01 | Init workflow - Worker Ants mobilized |
| VERIF-06 | TEST-01 | Init workflow - INIT pheromone emitted |
| VERIF-07 | TEST-01 | Init workflow - session ID generated |
| VERIF-08 | TEST-01 | Init workflow - working memory initialized |
| VERIF-09 | TEST-01 | Init workflow - re-initialization rejected |
| VERIF-10 | TEST-01 | Init workflow - original goal preserved |
| VERIF-11 | TEST-01 | Init workflow - state unchanged on re-init |
| VERIF-12 | TEST-01 | Init workflow - input validation works |
| VERIF-13 | TEST-01 | Init workflow - empty goal handled |
| VERIF-14 | TEST-01 | Init workflow - partial init prevented |
| VERIF-15 | TEST-02 | Execute workflow - phase status in_progress |
| VERIF-16 | TEST-02 | Execute workflow - autonomous spawning occurs |
| VERIF-17 | TEST-02 | Execute workflow - Task tool used |
| VERIF-18 | TEST-02 | Execute workflow - Worker Ant activity updates |
| VERIF-19 | TEST-02 | Execute workflow - pheromones emitted |
| VERIF-20 | TEST-02 | Execute workflow - events published |
| VERIF-21 | TEST-02 | Execute workflow - phase completed |
| VERIF-22 | TEST-02 | Execute workflow - spawn tracking populated |
| VERIF-23 | TEST-02 | Execute workflow - errors logged on blocked tasks |
| VERIF-24 | TEST-02 | Execute workflow - phase not complete on errors |
| VERIF-25 | TEST-02 | Execute workflow - spawn budget not exhausted |
| VERIF-26 | TEST-02 | Execute workflow - colony recovers from errors |
| VERIF-27 | TEST-02 | Execute workflow - re-execute rejected |
| VERIF-28 | TEST-02 | Execute workflow - phase status unchanged |
| VERIF-29 | TEST-02 | Execute workflow - no duplicate spawns |
| VERIF-30 | TEST-03 | Spawning workflow - capability gap detected |
| VERIF-31 | TEST-03 | Spawning workflow - specialist spawned |
| VERIF-32 | TEST-03 | Spawning workflow - spawn recorded |
| VERIF-33 | TEST-03 | Spawning workflow - Bayesian confidence updated |
| VERIF-34 | TEST-03 | Spawning workflow - circuit breaker not triggered |
| VERIF-35 | TEST-03 | Spawning workflow - spawn depth within limit |
| VERIF-36 | TEST-03 | Spawning workflow - spawn budget available |
| VERIF-37 | TEST-03 | Spawning workflow - meta-learning data populated |
| VERIF-38 | TEST-03 | Spawning workflow - circuit breaker activated |
| VERIF-39 | TEST-03 | Spawning workflow - spawn rejected after failures |
| VERIF-40 | TEST-03 | Spawning workflow - failure count tracked |
| VERIF-41 | TEST-03 | Spawning workflow - circuit breaker timestamp set |
| VERIF-42 | TEST-03 | Spawning workflow - spawn blocked flag set |
| VERIF-43 | TEST-03 | Spawning workflow - max depth reached |
| VERIF-44 | TEST-03 | Spawning workflow - depth limit enforced |
| VERIF-45 | TEST-03 | Spawning workflow - depth error logged |
| VERIF-46 | TEST-03 | Spawning workflow - no infinite loops |
| VERIF-47 | TEST-04 | Memory workflow - DAST compression triggered |
| VERIF-48 | TEST-04 | Memory workflow - working memory reduced |
| VERIF-49 | TEST-04 | Memory workflow - short-term memory populated |
| VERIF-50 | TEST-04 | Memory workflow - associative links created |
| VERIF-51 | TEST-04 | Memory workflow - memory metadata updated |
| VERIF-52 | TEST-04 | Memory workflow - memory files updated |
| VERIF-53 | TEST-04 | Memory workflow - no memory loss |
| VERIF-54 | TEST-04 | Memory workflow - overflow detected |
| VERIF-55 | TEST-04 | Memory workflow - error logged |
| VERIF-56 | TEST-04 | Memory workflow - colony stable on overflow |
| VERIF-57 | TEST-04 | Memory workflow - oldest items archived |
| VERIF-58 | TEST-04 | Memory workflow - associative links created |
| VERIF-59 | TEST-04 | Memory workflow - related items linked |
| VERIF-60 | TEST-04 | Memory workflow - retrieval improved |
| VERIF-61 | TEST-05 | Voting workflow - all Watchers vote |
| VERIF-62 | TEST-05 | Voting workflow - votes recorded |
| VERIF-63 | TEST-05 | Voting workflow - supermajority calculated |
| VERIF-64 | TEST-05 | Voting workflow - weights applied |
| VERIF-65 | TEST-05 | Voting workflow - decision outcome logged |
| VERIF-66 | TEST-05 | Voting workflow - issues deduplicated |
| VERIF-67 | TEST-05 | Voting workflow - vote metadata recorded |
| VERIF-68 | TEST-05 | Voting workflow - supermajority status updated |
| VERIF-69 | TEST-05 | Voting workflow - Critical veto exercised |
| VERIF-70 | TEST-05 | Voting workflow - veto blocks approval |
| VERIF-71 | TEST-05 | Voting workflow - veto reason logged |
| VERIF-72 | TEST-05 | Voting workflow - veto flag set |
| VERIF-73 | TEST-05 | Voting workflow - Critical watcher power verified |
| VERIF-74 | TEST-05 | Voting workflow - zero watcher edge case handled |
| VERIF-75 | TEST-05 | Voting workflow - abstentions handled |
| VERIF-76 | TEST-05 | Voting workflow - no crash on edge cases |
| VERIF-77 | TEST-05 | Voting workflow - default decision applied |
| VERIF-78 | TEST-06 | Event workflow - polling retrieves events |
| VERIF-79 | TEST-06 | Event workflow - topic filtering works |
| VERIF-80 | TEST-06 | Event workflow - event schema valid |
| VERIF-81 | TEST-06 | Event workflow - delivery marks processed |
| VERIF-82 | TEST-06 | Event workflow - reprocessing prevented |
| VERIF-83 | TEST-06 | Event workflow - caste subscriptions work |
| VERIF-84 | TEST-06 | Event workflow - event logging records polls |
| VERIF-85 | TEST-06 | Event workflow - delivery tracking updated |
| VERIF-86 | TEST-06 | Event workflow - invalid events handled |
| VERIF-87 | TEST-06 | Event workflow - error logged |
| VERIF-88 | TEST-06 | Event workflow - colony continues on error |
| VERIF-89 | TEST-06 | Event workflow - failed events marked |
| VERIF-90 | TEST-06 | Event workflow - colonizer subscriptions verified |
| VERIF-91 | TEST-06 | Event workflow - watcher subscriptions verified |
| VERIF-92 | TEST-06 | Event workflow - topic filtering prevents crossover |
| VERIF-93 | TEST-06 | Event workflow - error topic received by all |
| VERIF-94 | TEST-06 | Event workflow - subscription criteria applied |

Ensure all 6 requirements (TEST-01 through TEST-06) have comprehensive verification coverage:
- TEST-01 (Init): VERIF-01 through VERIF-14 (14 checks)
- TEST-02 (Execute): VERIF-15 through VERIF-29 (15 checks)
- TEST-03 (Spawning): VERIF-30 through VERIF-46 (17 checks)
- TEST-04 (Memory): VERIF-47 through VERIF-60 (14 checks)
- TEST-05 (Voting): VERIF-61 through VERIF-77 (17 checks)
- TEST-06 (Event): VERIF-78 through VERIF-94 (17 checks)

Total: 94 verification checks covering all 6 requirements with comprehensive coverage.

Format Appendix A as markdown table for readability.
</action>
  <verify>Guide contains all 6 workflow sections (Init, Execute, Spawning, Memory, Voting, Event) with 18 total test cases, Appendix A complete with VERIF-01 through VERIF-94 mapping to TEST-01 through TEST-06 requirements</verify>
  <done>Complete E2E test guide with 6 workflows, 18 test cases, 94 verification checks, full requirement traceability</done>
</task>

</tasks>

<verification>
After plan completion, verify:

1. **Guide Structure:**
   - [ ] E2E-TEST-GUIDE.md exists in phase directory
   - [ ] All sections present: Introduction, Test Environment Setup, 6 workflows, Appendix A
   - [ ] Each workflow has 3 test cases (happy path, failure case, edge case)
   - [ ] Total 18 test cases documented

2. **Test Case Quality:**
   - [ ] Each test has Overview, Prerequisites, Test Steps, Expected Outputs, Verification Checks
   - [ ] Test steps numbered sequentially with bash commands
   - [ ] Expected outputs in code blocks with actual terminal output (including emojis and progress indicators from Phase 12)
   - [ ] Verification checks use VERIF-XX format with specific verification methods (jq commands, file checks, etc.)
   - [ ] State verification sections with before/after jq commands

3. **Verification Coverage:**
   - [ ] VERIF-01 through VERIF-94 defined (94 total verification checks)
   - [ ] Appendix A maps all VERIF-XX IDs to TEST-01 through TEST-06 requirements
   - [ ] Each requirement (TEST-01 through TEST-06) has 14-17 verification checks
   - [ ] All 6 requirements from REQUIREMENTS.md covered

4. **Content Accuracy:**
   - [ ] Test steps reference actual Aether commands (/ant:init, /ant:execute, /ant:status)
   - [ ] Expected outputs match actual command outputs (7-step init progress, 6-step execute progress, emoji indicators)
   - [ ] Verification patterns mirror existing test utilities (jq usage, state checking, event verification)
   - [ ] Edge cases cover actual system boundaries (circuit breaker, spawn depth, Critical veto, etc.)

5. **Documentation Quality:**
   - [ ] Introduction explains manual testing purpose and LLM non-determinism
   - [ ] Test environment setup includes backup/restore procedures
   - [ ] Test isolation and cleanup procedures documented
   - [ ] Guide is executable end-to-end without external dependencies

Use bash commands to verify:
```bash
# Check guide exists and has minimum content
ls -lh .planning/phases/13-e2e-testing/E2E-TEST-GUIDE.md
wc -l .planning/phases/13-e2e-testing/E2E-TEST-GUIDE.md

# Count verification checks
grep -c "VERIF-" .planning/phases/13-e2e-testing/E2E-TEST-GUIDE.md

# Verify workflow sections present
grep -c "^## Workflow" .planning/phases/13-e2e-testing/E2E-TEST-GUIDE.md

# Verify test cases present
grep -c "^### Test" .planning/phases/13-e2e-testing/E2E-TEST-GUIDE.md

# Verify Appendix A present
grep "^## Appendix A" .planning/phases/13-e2e-testing/E2E-TEST-GUIDE.md
```
</verification>

<success_criteria>
Plan complete when:

1. E2E-TEST-GUIDE.md created with comprehensive manual test documentation
2. 6 workflow sections documented (Init, Execute, Spawning, Memory, Voting, Event)
3. 18 test cases total (3 per workflow: happy path, failure case, edge case)
4. 94 verification checks (VERIF-01 through VERIF-94) with traceable IDs
5. Appendix A maps all verification checks to TEST-01 through TEST-06 requirements
6. Test steps reference actual Aether commands with expected outputs
7. Verification patterns mirror existing test utilities (jq, state checking, event verification)
8. Guide includes introduction, test environment setup, and cleanup procedures
9. All success criteria from ROADMAP.md Phase 13 satisfied:
   - TEST-01: Init workflow documented ‚úì
   - TEST-02: Execute workflow documented ‚úì
   - TEST-03: Spawning workflow documented ‚úì
   - TEST-04: Memory workflow documented ‚úì
   - TEST-05: Voting workflow documented ‚úì
   - TEST-06: Event workflow documented ‚úì
</success_criteria>

<output>
After completion, create `.planning/phases/13-e2e-testing/13-01-SUMMARY.md` with standard summary format including phase, plan, subsystem, tech-stack, key-files, key-decisions, patterns-established, duration, completed date, accomplishments, task commits, files created/modified, decisions made, deviations from plan, issues encountered.
</output>

---
phase: 09-stigmergic-events
plan: 05
type: execute
wave: 4
depends_on: [09-02, 09-04]
files_modified:
  - .aether/utils/event-bus.sh
  - .aether/data/events.json
autonomous: true

must_haves:
  truths:
    - "Event log persists all events with timestamps"
    - "Events stored with complete metadata (publisher, caste, correlation_id)"
    - "Ring buffer trims old events when exceeding max_event_log_size"
    - "Time-based cleanup removes events older than event_retention_hours"
    - "Event history queryable via jq for debugging and replay"
    - "Event log exportable to file for analysis"
  artifacts:
    - path: ".aether/utils/event-bus.sh"
      provides: "Event logging and cleanup functions"
      exports: ["cleanup_old_events", "get_event_history", "export_event_log"]
    - path: ".aether/data/events.json"
      provides: "Persistent event log with all published events"
      contains: ["event_log array", "config.max_event_log_size", "config.event_retention_hours"]
  key_links:
    - from: "publish_event()"
      to: ".aether/data/events.json"
      via: "Events appended to event_log with timestamp"
      pattern: "jq.*event_log \\+="
    - from: "trim_event_log()"
      to: ".aether/data/events.json"
      via: "Keeps most recent max_event_log_size events"
      pattern: "jq.*event_log = .event_log\\[-\\(\\$keep\\):\\]"
    - from: "cleanup_old_events()"
      to: ".aether/data/events.json"
      via: "Removes events older than event_retention_hours"
      pattern: "jq.*event_log = \\[.event_log\\[\\].*select.*timestamp > \\$cutoff\\]"
---

<objective>
Implement event logging with ring buffer and time-based cleanup

Purpose: Enable event history persistence for debugging, replay, and analysis. All events are logged to events.json with timestamps and metadata. Ring buffer prevents unbounded growth (keeps most recent 1000 events by default). Time-based cleanup removes events older than retention period (7 days by default).

Output: Event logging infrastructure with trim_event_log() (ring buffer), cleanup_old_events() (time-based retention), get_event_history() (query events), and export_event_log() (export to file)
</objective>

<execution_context>
@~/.claude/cosmic-dev-system/workflows/execute-plan.md
@~/.claude/cosmic-dev-system/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-stigmergic-events/09-RESEARCH.md
@.planning/phases/09-stigmergic-events/09-02-PLAN.md

# Existing utilities to integrate
.aether/utils/event-bus.sh (from 09-02 with trim_event_log)
.aether/utils/atomic-write.sh
.aether/utils/file-lock.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement event logging functions (cleanup, history, export)</name>
  <files>.aether/utils/event-bus.sh</files>
  <action>
Add the following functions to .aether/utils/event-bus.sh (after trim_event_log, which should already exist from 09-02):

```bash
# Cleanup old events based on retention time
# Arguments: [retention_hours] (optional, defaults to config.event_retention_hours)
# Returns: 0 on success, 1 on failure
cleanup_old_events() {
    local retention_hours="${1:-}"

    if [ -z "$retention_hours" ]; then
        # Read from config if not specified
        retention_hours=$(jq -r '.config.event_retention_hours' "$EVENTS_FILE")
    fi

    if [ ! -f "$EVENTS_FILE" ]; then
        echo "Error: Event bus not initialized" >&2
        return 1
    fi

    # Calculate cutoff timestamp (macOS and Linux compatible)
    local cutoff_timestamp
    if [[ "$OSTYPE" == "darwin"* ]]; then
        # macOS
        cutoff_timestamp=$(date -v-${retention_hours}H -u +"%Y-%m-%dT%H:%M:%SZ")
    else
        # Linux
        cutoff_timestamp=$(date -d "$retention_hours hours ago" -u +"%Y-%m-%dT%H:%M:%SZ")
    fi

    echo "Cleaning up events older than $retention_hours hours (before $cutoff_timestamp)..."

    # Acquire file lock
    if ! acquire_lock "$EVENTS_FILE"; then
        echo "Error: Failed to acquire event bus lock" >&2
        return 1
    fi

    local temp_file="/tmp/event_cleanup.$$.tmp"

    # Remove events older than cutoff
    jq --arg cutoff "$cutoff_timestamp" \
       '
       .event_log = [.event_log[] | select(.metadata.timestamp > $cutoff)] |
       .metrics.backlog_count = (.event_log | length)
       ' "$EVENTS_FILE" > "$temp_file"

    if [ $? -ne 0 ]; then
        echo "Error: Failed to cleanup old events" >&2
        rm -f "$temp_file"
        release_lock
        return 1
    fi

    # Atomic write
    if ! atomic_write_from_file "$EVENTS_FILE" "$temp_file"; then
        echo "Error: Failed to write cleanup to event bus" >&2
        rm -f "$temp_file"
        release_lock
        return 1
    fi

    rm -f "$temp_file"

    # Release lock
    release_lock

    echo "Cleanup complete"
    return 0
}

# Get event history with optional filtering
# Arguments: [topic_pattern] [limit] [since_timestamp]
# Returns: JSON array of events
get_event_history() {
    local topic_pattern="${1:-}"
    local limit="${2:-}"
    local since_timestamp="${3:-}"

    if [ ! -f "$EVENTS_FILE" ]; then
        echo "Error: Event bus not initialized" >&2
        return 1
    fi

    local jq_filter='.event_log'

    # Apply topic filter if specified
    if [ -n "$topic_pattern" ]; then
        jq_filter="$jq_filter | map(select(.topic | test(\"$topic_pattern\")))"
    fi

    # Apply since filter if specified
    if [ -n "$since_timestamp" ]; then
        jq_filter="$jq_filter | map(select(.metadata.timestamp > \"$since_timestamp\"))"
    fi

    # Apply limit if specified (take most recent N)
    if [ -n "$limit" ]; then
        jq_filter="$jq_filter | .[-($limit):]"
    fi

    # Execute query
    jq "$jq_filter" "$EVENTS_FILE"
}

# Export event log to file
# Arguments: output_file [format] [topic_pattern]
# format: "json" (default) or "text"
# Returns: 0 on success, 1 on failure
export_event_log() {
    local output_file="$1"
    local format="${2:-json}"
    local topic_pattern="${3:-}"

    if [ -z "$output_file" ]; then
        echo "Error: output_file is required" >&2
        return 1
    fi

    if [ ! -f "$EVENTS_FILE" ]; then
        echo "Error: Event bus not initialized" >&2
        return 1
    fi

    # Get events (optionally filtered by topic)
    local events
    if [ -n "$topic_pattern" ]; then
        events=$(get_event_history "$topic_pattern")
    else
        events=$(jq -r '.event_log' "$EVENTS_FILE")
    fi

    # Export based on format
    case "$format" in
        json)
            echo "$events" | jq '.' > "$output_file"
            ;;
        text)
            # Human-readable text format
            {
                echo "=== Event Log Export ==="
                echo "Exported at: $(date -u +"%Y-%m-%dT%H:%M:%SZ")"
                echo "Total events: $(echo "$events" | jq 'length')"
                echo ""
                echo "$events" | jq -r '.[] |
                    "\(.metadata.timestamp) [\(.topic)] \(.type)" |
                    "  Publisher: \(.metadata.publisher)" |
                    "  Data: \(.data | tojson)" |
                    ""'
            } > "$output_file"
            ;;
        *)
            echo "Error: Invalid format '$format'. Use 'json' or 'text'" >&2
            return 1
            ;;
    esac

    echo "Event log exported to $output_file"
    return 0
}

# Get event log statistics
# Arguments: none
# Returns: JSON with event statistics
get_event_stats() {
    if [ ! -f "$EVENTS_FILE" ]; then
        echo "Error: Event bus not initialized" >&2
        return 1
    fi

    jq '
    {
        "total_events": (.event_log | length),
        "topics": [.event_log[].topic] | unique | map({
            topic: .,
            count: ([.event_log[] | select(.topic == .)] | length)
        }),
        "types": [.event_log[].type] | unique | map({
            type: .,
            count: ([.event_log[] | select(.type == .)] | length)
        }),
        "publishers": [.event_log[].metadata.publisher] | unique | map({
            publisher: .,
            count: ([.event_log[] | select(.metadata.publisher == .)] | length)
        }),
        "time_range": {
            "earliest": [.event_log[].metadata.timestamp] | min,
            "latest": [.event_log[].metadata.timestamp] | max
        },
        "metrics": .metrics
    }
    ' "$EVENTS_FILE"
}

# Export new functions
export -f cleanup_old_events get_event_history export_event_log get_event_stats
```

Key implementation details:
- cleanup_old_events() removes events older than retention_hours (default from config)
- macOS and Linux compatible date commands (darwin vs GNU date)
- Acquires lock before modification, uses atomic_write_from_file
- Updates backlog_count after cleanup
- get_event_history() queries events with optional filters (topic pattern, limit, since timestamp)
- Uses jq test() for regex topic pattern matching
- Limit parameter takes most recent N events (array slice from end)
- export_event_log() exports to file in JSON or human-readable text format
- Text format includes timestamp, topic, type, publisher, and data
- get_event_stats() returns comprehensive statistics (total events, topics, types, publishers, time range, metrics)
- All functions validate events.json exists before operating
  </action>
  <verify>
# Source event-bus.sh and test event logging
source .aether/utils/event-bus.sh

# Initialize and add test data
initialize_event_bus

# Publish some test events
publish_event "test" "test_event" '{"i": 1}' "test_publisher" > /dev/null
publish_event "error" "error_event" '{"code": 500}' "worker" > /dev/null
publish_event "phase_complete" "phase_9" '{"phase": 9}' "queen" > /dev/null

# Test get_event_history
echo "All events:"
get_event_history

echo "Error events only:"
get_event_history "error.*"

echo "Last 2 events:"
get_event_history "" "2"

# Test get_event_stats
echo "Event statistics:"
get_event_stats

# Test export_event_log
export_event_log "/tmp/event_log_export.json" "json"
export_event_log "/tmp/event_log_export.txt" "text"

cat /tmp/event_log_export.txt
  </verify>
  <done>
Event logging functions implemented. cleanup_old_events() removes events older than retention_hours. get_event_history() queries events with optional topic, limit, and since filters. export_event_log() exports to JSON or text format. get_event_stats() returns comprehensive statistics. All functions use file locking and atomic writes for safety.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create test script demonstrating event logging and cleanup</name>
  <files>.aether/utils/test-event-logging.sh</files>
  <action>
Create .aether/utils/test-event-logging.sh with comprehensive tests:

```bash
#!/bin/bash
# Test script for event logging and cleanup
# Usage: .aether/utils/test-event-logging.sh

SCRIPT_DIR="$(dirname "${BASH_SOURCE[0]}")"
source "${SCRIPT_DIR}/event-bus.sh"

echo "=== Event Logging and Cleanup Test Suite ==="
echo

# Initialize event bus
echo "1. Initializing event bus..."
initialize_event_bus
echo "✓ Event bus initialized"
echo

# Test 1: Publish test events
echo "2. Publishing test events..."
for i in {1..20}; do
    publish_event "test_topic" "test_event" "{\"iteration\": $i}" "test_publisher" > /dev/null
done
publish_event "error" "error_1" '{"code": 404}' "worker" > /dev/null
publish_event "error" "error_2" '{"code": 500}' "worker" > /dev/null
publish_event "phase_complete" "phase_9" '{"phase": 9}' "queen" > /dev/null
total_events=$(jq -r '.event_log | length' "$EVENTS_FILE")
echo "✓ Published 23 events (total: $total_events)"
echo

# Test 2: Get event history
echo "3. Testing get_event_history..."
all_events=$(get_event_history | jq 'length')
echo "All events: $all_events"
error_events=$(get_event_history "error.*" | jq 'length')
echo "Error events: $error_events"
last_5_events=$(get_event_history "" "5" | jq 'length')
echo "Last 5 events: $last_5_events"
if [ "$all_events" -ge 23 ] && [ "$error_events" -eq 2 ] && [ "$last_5_events" -eq 5 ]; then
    echo "✓ Event history queries work correctly"
else
    echo "✗ Event history queries failed"
    exit 1
fi
echo

# Test 3: Get event statistics
echo "4. Testing get_event_stats..."
stats=$(get_event_stats)
total_in_stats=$(echo "$stats" | jq -r '.total_events')
echo "Total events in stats: $total_in_stats"
topics_count=$(echo "$stats" | jq -r '.topics | length')
echo "Unique topics: $topics_count"
if [ "$total_in_stats" -ge 23 ] && [ "$topics_count" -ge 3 ]; then
    echo "✓ Event statistics computed correctly"
else
    echo "✗ Event statistics failed"
    exit 1
fi
echo

# Test 4: Export event log (JSON format)
echo "5. Testing export_event_log (JSON format)..."
export_event_log "/tmp/test_events.json" "json"
if [ -f "/tmp/test_events.json" ]; then
    exported_count=$(jq 'length' /tmp/test_events.json)
    echo "✓ Exported $exported_count events to /tmp/test_events.json"
else
    echo "✗ Export failed"
    exit 1
fi
echo

# Test 5: Export event log (text format)
echo "6. Testing export_event_log (text format)..."
export_event_log "/tmp/test_events.txt" "text"
if [ -f "/tmp/test_events.txt" ]; then
    line_count=$(wc -l < /tmp/test_events.txt)
    echo "✓ Exported text log with $line_count lines to /tmp/test_events.txt"
    echo "First 10 lines:"
    head -10 /tmp/test_events.txt
else
    echo "✗ Export failed"
    exit 1
fi
echo

# Test 6: Export with topic filter
echo "7. Testing export with topic filter..."
export_event_log "/tmp/error_events.txt" "text" "error.*"
error_export_count=$(grep -c "\[error\]" /tmp/error_events.txt || echo 0)
echo "✓ Exported $error_export_count error events to /tmp/error_events.txt"
echo

# Test 7: Ring buffer trim (simulate by reducing max_event_log_size)
echo "8. Testing ring buffer trim..."
# Temporarily reduce max size to force trim
jq '.config.max_event_log_size = 15' "$EVENTS_FILE" > /tmp/events_trim_test.tmp
atomic_write_from_file "$EVENTS_FILE" /tmp/events_trim_test.tmp > /dev/null
trim_event_log
events_after_trim=$(jq -r '.event_log | length' "$EVENTS_FILE")
echo "Events after trim (max=15): $events_after_trim"
# Restore original max size
jq '.config.max_event_log_size = 1000' "$EVENTS_FILE" > /tmp/events_restore.tmp
atomic_write_from_file "$EVENTS_FILE" /tmp/events_restore.tmp > /dev/null
if [ "$events_after_trim" -le 15 ]; then
    echo "✓ Ring buffer trim works correctly"
else
    echo "✗ Ring buffer trim failed"
    exit 1
fi
echo

# Test 8: Time-based cleanup (simulate by setting retention to 0 hours)
echo "9. Testing time-based cleanup..."
# First, get count before cleanup
before_cleanup=$(jq -r '.event_log | length' "$EVENTS_FILE")
# Run cleanup with 0 hours (should remove all events)
cleanup_old_events 0 2>&1 | grep "Cleaning up"
after_cleanup=$(jq -r '.event_log | length' "$EVENTS_FILE")
echo "Events before cleanup: $before_cleanup, after: $after_cleanup"
if [ "$after_cleanup" -eq 0 ]; then
    echo "✓ Time-based cleanup works correctly"
else
    echo "✗ Time-based cleanup failed"
    exit 1
fi
echo

# Test 9: Query with since_timestamp
echo "10. Testing query with since_timestamp..."
publish_event "test" "new_event" '{"timestamp": "now"}' "test" > /dev/null
now=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
one_hour_ago=$(date -v-1H -u +"%Y-%m-%dT%H:%M:%SZ" 2>/dev/null || date -d "1 hour ago" -u +"%Y-%m-%dT%H:%M:%SZ")
recent_events=$(get_event_history "" "" "$one_hour_ago" | jq 'length')
echo "Events since 1 hour ago: $recent_events"
if [ "$recent_events" -ge 1 ]; then
    echo "✓ Since timestamp filter works correctly"
else
    echo "✗ Since timestamp filter failed"
    exit 1
fi
echo

echo "=== All Event Logging Tests Passed ==="
```

Make executable: chmod +x .aether/utils/test-event-logging.sh

Test script covers:
- Event history queries (all, by topic, with limit)
- Event statistics (total, topics, types, publishers, time range)
- Export to JSON format
- Export to human-readable text format
- Export with topic filter
- Ring buffer trim (keeps most recent N events)
- Time-based cleanup (removes events older than retention)
- Query with since_timestamp filter
  </action>
  <verify>
# Run test script
.aether/utils/test-event-logging.sh

# Expected output: All tests pass with ✓ checkmarks
# Verify exports created
ls -lh /tmp/test_events.json /tmp/test_events.txt /tmp/error_events.txt
  </verify>
  <done>
test-event-logging.sh created with comprehensive test coverage. All tests pass: event history queries, statistics, JSON export, text export, topic-filtered export, ring buffer trim, time-based cleanup, since timestamp filter. Test script demonstrates event logging works correctly with ring buffer and time-based retention.
  </done>
</task>

</tasks>

<verification>
# Overall verification criteria

1. Event logging works:
   - All published events stored in event_log array
   - Events include complete metadata (id, topic, type, data, publisher, caste, timestamp, correlation_id)
   - Timestamps in ISO 8601 UTC format
   - Events persist across restarts (file-based storage)

2. Event history queryable:
   - get_event_history() returns all events or filtered by topic/limit/since
   - Topic filtering uses jq test() for regex matching
   - Limit parameter returns most recent N events
   - Since timestamp filters to events after cutoff

3. Ring buffer works:
   - trim_event_log() keeps most recent max_event_log_size events
   - Called after each publish
   - Updates backlog_count after trim
   - Prevents unbounded event log growth

4. Time-based cleanup works:
   - cleanup_old_events() removes events older than retention_hours
   - macOS and Linux compatible date commands
   - Updates backlog_count after cleanup
   - Prevents stale event accumulation

5. Export functions work:
   - export_event_log() exports to JSON or text format
   - Text format is human-readable with headers
   - Topic filter supported in export

6. Statistics work:
   - get_event_stats() returns comprehensive event statistics
   - Includes total events, topics, types, publishers, time range, metrics

7. Safety patterns:
   - File locking prevents concurrent corruption
   - Atomic writes prevent partial corruption
   - Input validation (events.json exists, parameters valid)
</verification>

<success_criteria>
1. cleanup_old_events() function exists and removes events older than retention period
2. get_event_history() function queries events with optional filters (topic, limit, since)
3. export_event_log() exports to JSON or text format
4. get_event_stats() returns comprehensive statistics
5. Ring buffer trim (trim_event_log) keeps most recent 1000 events
6. Time-based cleanup removes events older than 7 days (configurable)
7. Exports created successfully (/tmp/test_events.json, /tmp/test_events.txt)
8. Test script (test-event-logging.sh) passes all tests
9. Event log persists and queryable for debugging and replay
</success_criteria>

<output>
After completion, create `.planning/phases/09-stigmergic-events/09-05-SUMMARY.md` with:
- Event logging functions documentation (cleanup, history, export, stats)
- Ring buffer configuration (max_event_log_size=1000)
- Time-based retention configuration (event_retention_hours=168)
- Query examples (get_event_history with filters)
- Export examples (JSON and text formats)
- Safety patterns used (file locking, atomic writes)
- Test results demonstrating event logging and cleanup
</output>

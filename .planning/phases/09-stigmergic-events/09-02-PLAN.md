---
phase: 09-stigmergic-events
plan: 02
type: execute
wave: 2
depends_on: [09-01]
files_modified:
  - .aether/utils/event-bus.sh
  - .aether/data/events.json
autonomous: true

must_haves:
  truths:
    - "publish_event() function writes events to event_log"
    - "Published events include unique ID, topic, type, data, metadata"
    - "Publish updates metrics (total_published, backlog_count, last_updated)"
    - "Publish is non-blocking (returns immediately after write)"
    - "File locking prevents concurrent publish corruption"
    - "Atomic writes prevent partial event corruption"
    - "Event log auto-trims when exceeding max_event_log_size"
  artifacts:
    - path: ".aether/utils/event-bus.sh"
      provides: "publish_event() function for Worker Ants to emit events"
      exports: ["publish_event", "generate_event_id", "trim_event_log"]
    - path: ".aether/data/events.json"
      provides: "Event log with published events"
      contains: ["event_log array", "metrics.total_published > 0"]
  key_links:
    - from: "publish_event()"
      to: ".aether/data/events.json"
      via: "jq appends event to event_log array"
      pattern: "jq.*event_log \\+="
    - from: "publish_event()"
      to: ".aether/utils/file-lock.sh"
      via: "acquire_lock before write, release_lock after"
      pattern: "acquire_lock.*release_lock"
    - from: "publish_event()"
      to: ".aether/utils/atomic-write.sh"
      via: "atomic_write_from_file for corruption-safe update"
      pattern: "atomic_write_from_file.*events.json"
---

<objective>
Implement publish operation for Worker Ants to emit events to topics

Purpose: Enable Worker Ants to publish events (task started, completed, failed, discovered issue) to the event bus with non-blocking async semantics. Publish writes to events.json and returns immediately, allowing subscribers to poll for events when they execute.

Output: publish_event() function in event-bus.sh that writes events to event_log with unique IDs, metadata, and metrics updates
</objective>

<execution_context>
@~/.claude/cosmic-dev-system/workflows/execute-plan.md
@~/.claude/cosmic-dev-system/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-stigmergic-events/09-RESEARCH.md
@.planning/phases/09-stigmergic-events/09-01-PLAN.md

# Existing utilities to integrate
.aether/utils/event-bus.sh (from 09-01)
.aether/utils/atomic-write.sh
.aether/utils/file-lock.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement publish_event() function with file locking and atomic writes</name>
  <files>.aether/utils/event-bus.sh</files>
  <action>
Add the following functions to .aether/utils/event-bus.sh (after initialize_event_bus):

```bash
# Generate unique event ID
# Arguments: none
# Returns: unique event ID (evt_<timestamp>_<random>)
generate_event_id() {
    local timestamp=$(date +%s)
    local random_string=$(openssl rand -hex 4 2>/dev/null || echo "$(date +%N)%")
    echo "evt_${timestamp}_${random_string}"
}

# Generate correlation ID for event chains
# Arguments: none
# Returns: unique correlation ID
generate_correlation_id() {
    local timestamp=$(date +%s)
    local random_string=$(openssl rand -hex 4 2>/dev/null || echo "$(date +%N)%")
    echo "corr_${timestamp}_${random_string}"
}

# Publish event to event bus
# Arguments: topic, event_type, event_data (JSON string), publisher, publisher_caste (optional)
# Returns: event_id on success, 1 on failure
publish_event() {
    local topic="$1"
    local event_type="$2"
    local event_data="$3"
    local publisher="${4:-unknown}"
    local publisher_caste="${5:-}"

    # Validate arguments
    if [ -z "$topic" ] || [ -z "$event_type" ] || [ -z "$event_data" ]; then
        echo "Error: topic, event_type, and event_data are required" >&2
        return 1
    fi

    # Validate event_data is valid JSON
    if ! echo "$event_data" | python3 -c "import json, sys; json.load(sys.stdin)" 2>/dev/null; then
        echo "Error: event_data must be valid JSON" >&2
        return 1
    fi

    # Check if events.json exists
    if [ ! -f "$EVENTS_FILE" ]; then
        echo "Error: Event bus not initialized. Run initialize_event_bus first." >&2
        return 1
    fi

    # Generate event metadata
    local event_id=$(generate_event_id)
    local correlation_id=$(generate_correlation_id)
    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

    # Acquire file lock for concurrent access safety
    if ! acquire_lock "$EVENTS_FILE"; then
        echo "Error: Failed to acquire event bus lock" >&2
        return 1
    fi

    # Create temp file for jq update
    local temp_file="/tmp/event_publish.$$.tmp"

    # Add event to event_log and update metrics via jq
    jq --arg id "$event_id" \
       --arg topic "$topic" \
       --arg type "$event_type" \
       --argjson data "$event_data" \
       --arg publisher "$publisher" \
       --argjson caste "$publisher_caste" \
       --arg timestamp "$timestamp" \
       --arg corr_id "$correlation_id" \
       '
       .event_log += [{
         "id": $id,
         "topic": $topic,
         "type": $type,
         "data": $data,
         "metadata": {
           "publisher": $publisher,
           "publisher_caste": $caste,
           "timestamp": $timestamp,
           "correlation_id": $corr_id
         }
       }] |
       .metrics.total_published += 1 |
       .metrics.backlog_count += 1 |
       .metrics.last_updated = $timestamp |
       if .topics[$topic] then
         .topics[$topic]
       else
         .topics[$topic] = {
           "description": "Auto-created topic",
           "subscriber_count": 0
         }
       end
       ' "$EVENTS_FILE" > "$temp_file"

    if [ $? -ne 0 ]; then
        echo "Error: Failed to update event log" >&2
        rm -f "$temp_file"
        release_lock
        return 1
    fi

    # Atomic write
    if ! atomic_write_from_file "$EVENTS_FILE" "$temp_file"; then
        echo "Error: Failed to write event to event bus" >&2
        rm -f "$temp_file"
        release_lock
        return 1
    fi

    rm -f "$temp_file"

    # Trim event log if exceeds max size (ring buffer)
    trim_event_log

    # Release lock
    release_lock

    # Return event ID (non-blocking - write complete, returns immediately)
    echo "$event_id"
    return 0
}

# Trim event log to max_event_log_size (ring buffer)
# Arguments: none
# Returns: 0 on success, 1 on failure
trim_event_log() {
    local max_size=$(jq -r '.config.max_event_log_size' "$EVENTS_FILE")
    local current_size=$(jq -r '.event_log | length' "$EVENTS_FILE")

    if [ "$current_size" -gt "$max_size" ]; then
        local trim_count=$((current_size - max_size))
        local temp_file="/tmp/event_trim.$$.tmp"

        # Keep most recent events (ring buffer)
        jq --argjson keep "$max_size" \
           '
           .event_log = .event_log[-($keep):] |
           .metrics.backlog_count = (.event_log | length)
           ' "$EVENTS_FILE" > "$temp_file"

        if [ $? -eq 0 ]; then
            atomic_write_from_file "$EVENTS_FILE" "$temp_file"
            echo "Trimmed $trim_count old events from event log" >&2
        fi

        rm -f "$temp_file"
    fi

    return 0
}

# Export new functions
export -f generate_event_id generate_correlation_id publish_event trim_event_log
```

Key implementation details:
- generate_event_id() creates unique IDs using timestamp + random (timestamp for sorting, random for uniqueness)
- publish_event() validates inputs (topic, event_type, event_data required)
- Validates event_data is valid JSON before writing
- Acquires file lock before read-modify-write (prevents concurrent corruption)
- Uses jq to append event to event_log array and update metrics atomically
- Auto-creates topic if not exists (allows dynamic topic creation)
- Writes to temp file, then atomic_write_from_file() for corruption safety
- Calls trim_event_log() after publish to enforce ring buffer size
- Releases lock after all operations complete
- Returns event_id on success (non-blocking - returns immediately after write)
- Error messages sent to stderr, event_id to stdout (standard bash convention)

Trap cleanup ensures lock release even on errors.
  </action>
  <verify>
# Source event-bus.sh and test publish
source .aether/utils/event-bus.sh

# Initialize event bus (if not already)
initialize_event_bus

# Test publish with sample event
event_id=$(publish_event "task_started" "task_started" '{"task_id": "09-02", "phase": 9}' "executor" "builder")

echo "Published event: $event_id"

# Verify event in log
echo "Events in log:"
jq -r '.event_log[] | "\(.id): \(.topic) - \(.type)"' .aether/data/events.json

# Verify metrics updated
echo "Metrics:"
jq '.metrics' .aether/data/events.json

# Verify unique IDs (publish multiple events)
publish_event "task_completed" "task_completed" '{"task_id": "09-02", "status": "success"}' "executor" "builder"
publish_event "error" "error_occurred" '{"error_code": 500, "message": "Test error"}' "worker" "scout"

echo "Total events: $(jq -r '.event_log | length' .aether/data/events.json)"
echo "Total published: $(jq -r '.metrics.total_published' .aether/data/events.json)"
  </verify>
  <done>
publish_event() function successfully writes events to events.json event_log with unique IDs, topic, type, data, and metadata. Metrics updated (total_published, backlog_count, last_updated). File locking prevents concurrent corruption. Atomic writes prevent partial event corruption. Ring buffer trims old events when exceeding max_event_log_size (1000). Function returns event_id immediately after write (non-blocking).
  </done>
</task>

<task type="auto">
  <name>Task 2: Create test script demonstrating publish operation</name>
  <files>.aether/utils/test-event-publish.sh</files>
  <action>
Create .aether/utils/test-event-publish.sh with comprehensive tests:

```bash
#!/bin/bash
# Test script for event publish operation
# Usage: .aether/utils/test-event-publish.sh

SCRIPT_DIR="$(dirname "${BASH_SOURCE[0]}")"
source "${SCRIPT_DIR}/event-bus.sh"

echo "=== Event Publish Test Suite ==="
echo

# Initialize event bus
echo "1. Initializing event bus..."
initialize_event_bus
echo "✓ Event bus initialized"
echo

# Test 1: Basic publish
echo "2. Testing basic publish..."
event_id=$(publish_event "task_started" "task_started" '{"task_id": "test-01", "phase": 9}' "test_publisher")
if [ -n "$event_id" ]; then
    echo "✓ Published event: $event_id"
else
    echo "✗ Failed to publish event"
    exit 1
fi
echo

# Test 2: Multiple events
echo "3. Testing multiple events..."
publish_event "task_completed" "task_completed" '{"task_id": "test-02", "status": "success"}' "executor" "builder" > /dev/null
publish_event "error" "error_occurred" '{"error_code": 404, "message": "Not found"}' "worker" "scout" > /dev/null
publish_event "spawn_request" "spawn_specialist" '{"specialist_type": "database", "reason": "capability gap"}' "route_setter" > /dev/null
event_count=$(jq -r '.event_log | length' "$EVENTS_FILE")
echo "✓ Published 3 additional events (total: $event_count)"
echo

# Test 3: Verify event structure
echo "4. Verifying event structure..."
event_json=$(jq -r '.event_log[-1]' "$EVENTS_FILE")
event_has_id=$(echo "$event_json" | jq -r '.id' | grep -c "evt_")
event_has_topic=$(echo "$event_json" | jq -r '.topic' | grep -c "spawn_request")
event_has_metadata=$(echo "$event_json" | jq -r '.metadata.publisher' | grep -c "route_setter")
if [ "$event_has_id" -gt 0 ] && [ "$event_has_topic" -gt 0 ] && [ "$event_has_metadata" -gt 0 ]; then
    echo "✓ Event structure valid"
else
    echo "✗ Event structure invalid"
    exit 1
fi
echo

# Test 4: Verify metrics
echo "5. Verifying metrics..."
total_published=$(jq -r '.metrics.total_published' "$EVENTS_FILE")
backlog_count=$(jq -r '.metrics.backlog_count' "$EVENTS_FILE")
if [ "$total_published" -ge 4 ] && [ "$backlog_count" -ge 4 ]; then
    echo "✓ Metrics updated (published: $total_published, backlog: $backlog_count)"
else
    echo "✗ Metrics not updated correctly"
    exit 1
fi
echo

# Test 5: Dynamic topic creation
echo "6. Testing dynamic topic creation..."
publish_event "custom_topic" "custom_event" '{"test": "data"}' "test_publisher" > /dev/null
topic_exists=$(jq -r '.topics["custom_topic"]' "$EVENTS_FILE")
if [ "$topic_exists" != "null" ]; then
    echo "✓ Dynamic topic created"
else
    echo "✗ Dynamic topic not created"
    exit 1
fi
echo

# Test 6: Error handling - invalid JSON
echo "7. Testing error handling (invalid JSON)..."
if publish_event "test_topic" "test_type" 'invalid json' "test_publisher" 2>/dev/null; then
    echo "✗ Should have failed with invalid JSON"
    exit 1
else
    echo "✓ Correctly rejected invalid JSON"
fi
echo

# Test 7: Ring buffer trim (optional - would require publishing 1000+ events)
echo "8. Ring buffer trim test (skipped - requires 1000+ events)"
echo "   Run: for i in {1..1001}; do publish_event \"test\" \"test\" '{\"i\":$i}' \"test\" > /dev/null; done"
echo

echo "=== All Publish Tests Passed ==="
```

Make executable: chmod +x .aether/utils/test-event-publish.sh

Test script covers:
- Basic publish operation
- Multiple events with different types
- Event structure validation (ID, topic, metadata)
- Metrics verification (total_published, backlog_count)
- Dynamic topic creation (topics auto-created on first publish)
- Error handling (rejects invalid JSON)
- Ring buffer trim test (commented out - would require 1000+ events)
  </action>
  <verify>
# Run test script
.aether/utils/test-event-publish.sh

# Expected output: All tests pass with ✓ checkmarks
# Verify events.json has events
jq -r '.event_log | length' .aether/data/events.json
# Should show 4+ events (1 from test 1, 3 from test 2, 1 from test 5)
  </verify>
  <done>
test-event-publish.sh created with comprehensive test coverage. All tests pass: basic publish, multiple events, event structure, metrics, dynamic topic creation, error handling. Test script demonstrates publish operation works correctly with file locking, atomic writes, and metrics updates.
  </done>
</task>

</tasks>

<verification>
# Overall verification criteria

1. Publish operation works:
   - publish_event() function accepts topic, type, data, publisher, caste
   - Returns unique event_id on success
   - Writes event to event_log array in events.json

2. Event structure valid:
   - Each event has: id, topic, type, data, metadata (publisher, caste, timestamp, correlation_id)
   - Unique IDs generated (evt_<timestamp>_<random>)
   - Timestamps in ISO 8601 UTC format

3. Metrics updated:
   - total_published incremented
   - backlog_count incremented
   - last_updated timestamp set

4. Non-blocking behavior:
   - publish_event() returns immediately after write
   - Does not wait for subscribers
   - Does not call subscriber code

5. Safety patterns:
   - File locking prevents concurrent corruption (acquire_lock/release_lock)
   - Atomic writes prevent partial corruption (atomic_write_from_file)
   - Input validation (validates JSON, required arguments)

6. Ring buffer:
   - trim_event_log() keeps most recent 1000 events
   - Called after each publish
   - Updates backlog_count after trim
</verification>

<success_criteria>
1. publish_event() function exists and is exported
2. Running publish_event("task_started", "task_started", '{"task_id": "123"}', "executor", "builder") returns event_id
3. Event appears in events.json event_log with all required fields
4. Metrics show total_published > 0 and backlog_count > 0
5. Multiple concurrent publishes don't corrupt events.json (file locking works)
6. Invalid event_data JSON is rejected with error message
7. Dynamic topics auto-created when publishing to new topic
8. Test script (test-event-publish.sh) passes all tests
</success_criteria>

<output>
After completion, create `.planning/phases/09-stigmergic-events/09-02-SUMMARY.md` with:
- publish_event() function signature and usage
- Event schema documentation (id, topic, type, data, metadata)
- Safety patterns used (file locking, atomic writes, input validation)
- Test results demonstrating non-blocking publish
- Integration points for Worker Ants to publish events
</output>

---
phase: 09-stigmergic-events
plan: 07
type: execute
wave: 4
depends_on: [09-02, 09-03, 09-04]
files_modified:
  - .aether/utils/event-metrics.sh
  - .aether/data/events.json
autonomous: true

must_haves:
  truths:
    - "Event metrics track publish rate, subscriptions, delivery latency, backlog"
    - "publish_rate_per_minute calculated from events in last 60 seconds"
    - "average_delivery_latency_ms tracks time from publish to delivery"
    - "backlog_count shows undelivered events per subscription"
    - "Metrics updated on publish, subscribe, and delivery operations"
    - "get_event_metrics() returns current metrics in JSON format"
    - "Metrics queryable for monitoring and debugging"
  artifacts:
    - path: ".aether/utils/event-metrics.sh"
      provides: "Event metrics tracking functions"
      exports: ["update_event_metrics", "get_event_metrics", "calculate_publish_rate", "calculate_delivery_latency"]
    - path: ".aether/data/events.json"
      provides: "Metrics section with real-time event statistics"
      contains: ["metrics object with publish_rate_per_minute, total_delivered, backlog_count"]
  key_links:
    - from: "publish_event()"
      to: "metrics in events.json"
      via: "Updates total_published, backlog_count, last_updated"
      pattern: "jq.*metrics.total_published \\+="
    - from: "subscribe_to_events()"
      to: "metrics in events.json"
      via: "Updates total_subscriptions"
      pattern: "jq.*metrics.total_subscriptions \\+="
    - from: "mark_events_delivered()"
      to: "metrics in events.json"
      via: "Updates total_delivered, backlog_count"
      pattern: "jq.*metrics.total_delivered \\+="
---

<objective>
Implement event metrics tracking for monitoring and observability

Purpose: Track event bus performance metrics including publish rate (events per minute), delivery latency (time from publish to delivery), subscription count, and backlog (undelivered events). Metrics enable monitoring, debugging, and performance optimization of the event bus.

Output: event-metrics.sh utility with metrics calculation functions and integration with event-bus.sh operations
</objective>

<execution_context>
@~/.claude/cosmic-dev-system/workflows/execute-plan.md
@~/.claude/cosmic-dev-system/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-stigmergic-events/09-RESEARCH.md
@.planning/phases/09-stigmergic-events/09-02-PLAN.md
@.planning/phases/09-stigmergic-events/09-03-PLAN.md
@.planning/phases/09-stigmergic-events/09-04-PLAN.md

# Existing utilities to integrate
.aether/utils/event-bus.sh (from 09-02, 09-03, 09-04)
.aether/utils/atomic-write.sh
.aether/utils/file-lock.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create event-metrics.sh with metrics calculation functions</name>
  <files>.aether/utils/event-metrics.sh</files>
  <action>
Create .aether/utils/event-metrics.sh with comprehensive metrics tracking:

```bash
#!/bin/bash
# Aether Event Metrics Utility
# Tracks event bus performance metrics for monitoring and observability
#
# Usage:
#   source .aether/utils/event-metrics.sh
#   get_event_metrics
#   calculate_publish_rate
#   calculate_delivery_latency

# Event bus storage file (same as event-bus.sh)
EVENTS_FILE="$(git rev-parse --show-toplevel 2>/dev/null || echo "$PWD")/.aether/data/events.json"

# Source required utilities
SCRIPT_DIR="$(dirname "${BASH_SOURCE[0]}")"
source "${SCRIPT_DIR}/atomic-write.sh"
source "${SCRIPT_DIR}/file-lock.sh"

# Calculate publish rate (events per minute)
# Arguments: none
# Returns: events published in last 60 seconds
calculate_publish_rate() {
    if [ ! -f "$EVENTS_FILE" ]; then
        echo "Error: Event bus not initialized" >&2
        return 1
    fi

    # Calculate cutoff timestamp (60 seconds ago)
    local one_minute_ago
    if [[ "$OSTYPE" == "darwin"* ]]; then
        one_minute_ago=$(date -v-60S -u +"%Y-%m-%dT%H:%M:%SZ")
    else
        one_minute_ago=$(date -d "60 seconds ago" -u +"%Y-%m-%dT%H:%M:%SZ")
    fi

    # Count events published since cutoff
    local count=$(jq -r --arg cutoff "$one_minute_ago" \
        '[.event_log[] | select(.metadata.timestamp > $cutoff)] | length' \
        "$EVENTS_FILE")

    echo "$count"
}

# Calculate average delivery latency
# Arguments: none
# Returns: average milliseconds from publish to delivery
calculate_delivery_latency() {
    if [ ! -f "$EVENTS_FILE" ]; then
        echo "Error: Event bus not initialized" >&2
        return 1
    fi

    # Get all subscriptions with delivery data
    local subscriptions=$(jq -c '.subscriptions[] | select(.delivery_count > 0)' "$EVENTS_FILE")

    if [ -z "$subscriptions" ]; then
        echo "0"
        return 0
    fi

    # Calculate average latency across all subscriptions
    # Latency = time from publish to first delivery after publish
    # This is approximated by checking event timestamps vs delivery timestamps
    local total_latency=0
    local count=0

    while IFS= read -r sub; do
        local last_delivered=$(echo "$sub" | jq -r '.last_event_delivered')
        if [ "$last_delivered" != "null" ] && [ -n "$last_delivered" ]; then
            # Get the most recent event before last_delivered
            local recent_event=$(jq -r --arg cutoff "$last_delivered" \
                '[.event_log[] | select(.metadata.timestamp <= $cutoff)] | max_by(.metadata.timestamp)' \
                "$EVENTS_FILE" 2>/dev/null)

            if [ -n "$recent_event" ] && [ "$recent_event" != "null" ]; then
                local event_timestamp=$(echo "$recent_event" | jq -r '.metadata.timestamp')
                # Calculate latency in milliseconds (approximation)
                # This is a simplified calculation - real latency would need delivery_timestamp per event
                local latency_ms=0  # Would need actual delivery timestamps

                # For now, use a simple heuristic: if backlog > 0, there's latency
                local backlog=$(jq -r '.metrics.backlog_count' "$EVENTS_FILE")
                if [ "$backlog" -gt 0 ]; then
                    latency_ms=100  # Placeholder: 100ms latency when backlog exists
                fi

                total_latency=$((total_latency + latency_ms))
                count=$((count + 1))
            fi
        fi
    done <<< "$subscriptions"

    if [ "$count" -gt 0 ]; then
        echo $((total_latency / count))
    else
        echo "0"
    fi
}

# Update event metrics
# Arguments: operation ("publish", "subscribe", "deliver")
# Returns: 0 on success, 1 on failure
update_event_metrics() {
    local operation="$1"

    if [ ! -f "$EVENTS_FILE" ]; then
        echo "Error: Event bus not initialized" >&2
        return 1
    fi

    local timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
    local publish_rate=$(calculate_publish_rate)

    # Acquire lock
    if ! acquire_lock "$EVENTS_FILE"; then
        echo "Error: Failed to acquire event bus lock" >&2
        return 1
    fi

    local temp_file="/tmp/event_metrics.$$.tmp"

    case "$operation" in
        publish)
            jq --arg now "$timestamp" \
               --argjson rate "$publish_rate" \
               '.metrics.publish_rate_per_minute = $rate |
                .metrics.last_updated = $now' \
               "$EVENTS_FILE" > "$temp_file"
            ;;
        subscribe)
            # publish_rate updated on publish, subscribe just updates timestamp
            jq --arg now "$timestamp" \
               '.metrics.last_updated = $now' \
               "$EVENTS_FILE" > "$temp_file"
            ;;
        deliver)
            local delivery_latency=$(calculate_delivery_latency)
            jq --arg now "$timestamp" \
               --argjson latency "$delivery_latency" \
               '.metrics.average_delivery_latency_ms = $latency |
                .metrics.last_updated = $now' \
               "$EVENTS_FILE" > "$temp_file"
            ;;
        *)
            echo "Error: Unknown operation '$operation'" >&2
            rm -f "$temp_file"
            release_lock
            return 1
            ;;
    esac

    if [ $? -ne 0 ]; then
        echo "Error: Failed to update metrics" >&2
        rm -f "$temp_file"
        release_lock
        return 1
    fi

    # Atomic write
    if ! atomic_write_from_file "$EVENTS_FILE" "$temp_file"; then
        echo "Error: Failed to write metrics update" >&2
        rm -f "$temp_file"
        release_lock
        return 1
    fi

    rm -f "$temp_file"

    # Release lock
    release_lock

    return 0
}

# Get event metrics
# Arguments: none
# Returns: JSON with current metrics
get_event_metrics() {
    if [ ! -f "$EVENTS_FILE" ]; then
        echo "Error: Event bus not initialized" >&2
        return 1
    fi

    # Get base metrics
    local base_metrics=$(jq '.metrics' "$EVENTS_FILE")

    # Calculate real-time metrics
    local publish_rate=$(calculate_publish_rate)
    local delivery_latency=$(calculate_delivery_latency)
    local backlog_count=$(jq -r '.metrics.backlog_count' "$EVENTS_FILE")
    local total_subscribers=$(jq -r '.subscriptions | length' "$EVENTS_FILE")

    # Combine base and real-time metrics
    jq -n \
        --argjson base "$base_metrics" \
        --argjson rate "$publish_rate" \
        --argjson latency "$delivery_latency" \
        --argjson backlog "$backlog_count" \
        --argjson subscribers "$total_subscribers" \
        '{
            total_published: $base.total_published,
            total_subscriptions: $base.total_subscriptions,
            total_delivered: $base.total_delivered,
            total_subscribers: $subscribers,
            publish_rate_per_minute: $rate,
            average_delivery_latency_ms: $latency,
            backlog_count: $backlog,
            last_updated: $base.last_updated
        }'
}

# Get metrics summary (human-readable)
# Arguments: none
# Returns: Formatted metrics summary
get_metrics_summary() {
    local metrics=$(get_event_metrics)

    echo "=== Event Bus Metrics ==="
    echo "Total Published: $(echo "$metrics" | jq -r '.total_published')"
    echo "Total Subscriptions: $(echo "$metrics" | jq -r '.total_subscriptions')"
    echo "Total Subscribers: $(echo "$metrics" | jq -r '.total_subscribers')"
    echo "Total Delivered: $(echo "$metrics" | jq -r '.total_delivered')"
    echo "Publish Rate: $(echo "$metrics" | jq -r '.publish_rate_per_minute') events/min"
    echo "Avg Delivery Latency: $(echo "$metrics" | jq -r '.average_delivery_latency_ms') ms"
    echo "Backlog: $(echo "$metrics" | jq -r '.backlog_count') events"
    echo "Last Updated: $(echo "$metrics" | jq -r '.last_updated')"
    echo "========================="
}

# Export functions
export -f calculate_publish_rate calculate_delivery_latency update_event_metrics get_event_metrics get_metrics_summary
```

Key implementation details:
- calculate_publish_rate() counts events in last 60 seconds (sliding window)
- calculate_delivery_latency() approximates latency (placeholder - would need per-event delivery timestamps)
- update_event_metrics() updates metrics for publish/subscribe/deliver operations
- get_event_metrics() combines base metrics with real-time calculations
- get_metrics_summary() provides human-readable output
- All operations use file locking and atomic writes
- macOS and Linux compatible date commands
  </action>
  <verify>
# Source event-metrics.sh and test metrics
source .aether/utils/event-metrics.sh

# Initialize event bus (if needed)
source .aether/utils/event-bus.sh
initialize_event_bus

# Publish some test events
publish_event "test" "test_event" '{"i": 1}' "test_publisher" > /dev/null
publish_event "test" "test_event" '{"i": 2}' "test_publisher" > /dev/null
publish_event "test" "test_event" '{"i": 3}' "test_publisher" > /dev/null

# Get metrics
echo "Current metrics:"
get_event_metrics

echo "Metrics summary:"
get_metrics_summary
  </verify>
  <done>
event-metrics.sh created with calculate_publish_rate(), calculate_delivery_latency(), update_event_metrics(), get_event_metrics(), and get_metrics_summary() functions. Publish rate calculated from events in last 60 seconds. Delivery latency approximated (placeholder for per-event timestamps). Metrics updated on publish/subscribe/deliver operations. All functions use file locking and atomic writes.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate metrics into event-bus.sh operations</name>
  <files>.aether/utils/event-bus.sh</files>
  <action>
Update event-bus.sh to integrate metrics tracking:

1. Source event-metrics.sh at the top of event-bus.sh (after atomic-write.sh and file-lock.sh):

```bash
# Source required utilities
SCRIPT_DIR="$(dirname "${BASH_SOURCE[0]}")"
source "${SCRIPT_DIR}/atomic-write.sh"
source "${SCRIPT_DIR}/file-lock.sh"
source "${SCRIPT_DIR}/event-metrics.sh"  # Add this line
```

2. Update publish_event() to call update_event_metrics after publishing:

Find the line in publish_event() that releases the lock, and add metrics update before it:

```bash
# Trim event log if exceeds max size (ring buffer)
trim_event_log

# Update publish metrics
update_event_metrics "publish" > /dev/null 2>&1

# Release lock
release_lock

# Return event ID (non-blocking - write complete, returns immediately)
echo "$event_id"
return 0
```

3. Update subscribe_to_events() to call update_event_metrics after subscribing:

Add after the atomic_write_from_file call:

```bash
rm -f "$temp_file"

# Update subscribe metrics
update_event_metrics "subscribe" > /dev/null 2>&1

# Release lock
release_lock

# Return subscription ID
echo "$sub_id"
return 0
```

4. Update mark_events_delivered() to call update_event_metrics after marking delivered:

Add after the atomic_write_from_file call:

```bash
rm -f "$temp_file"

# Update delivery metrics
update_event_metrics "deliver" > /dev/null 2>&1

# Release lock
release_lock

return 0
```

This integration ensures:
- Metrics automatically updated on publish (publish rate, total_published, backlog)
- Metrics updated on subscribe (total_subscriptions)
- Metrics updated on delivery (total_delivered, delivery latency, backlog)
- All metrics operations use file locking and atomic writes
- Errors from metrics updates don't fail the main operation (> /dev/null 2>&1)
  </action>
  <verify>
# Source updated event-bus.sh and test metrics integration
source .aether/utils/event-bus.sh

# Initialize event bus
initialize_event_bus

# Create subscription
subscribe_to_events "metrics_test" "watcher" "test_topic" '{}' > /dev/null

# Publish events
publish_event "test_topic" "test_event" '{"i": 1}' "publisher" > /dev/null
publish_event "test_topic" "test_event" '{"i": 2}' "publisher" > /dev/null
publish_event "test_topic" "test_event" '{"i": 3}' "publisher" > /dev/null

# Get and deliver events
events=$(get_events_for_subscriber "metrics_test" "watcher")
mark_events_delivered "metrics_test" "watcher" "$events" > /dev/null

# Check metrics updated
echo "Metrics after operations:"
get_metrics_summary

# Verify specific metrics
total_published=$(jq -r '.metrics.total_published' .aether/data/events.json)
total_subscriptions=$(jq -r '.metrics.total_subscriptions' .aether/data/events.json)
total_delivered=$(jq -r '.metrics.total_delivered' .aether/data/events.json)
publish_rate=$(jq -r '.metrics.publish_rate_per_minute' .aether/data/events.json)

echo "Verification:"
echo "  total_published: $total_published (expected >= 3)"
echo "  total_subscriptions: $total_subscriptions (expected >= 1)"
echo "  total_delivered: $total_delivered (expected >= 3)"
echo "  publish_rate_per_minute: $publish_rate (expected >= 3)"
  </verify>
  <done>
event-metrics.sh integrated into event-bus.sh. Metrics automatically updated on publish (total_published, publish_rate, backlog), subscribe (total_subscriptions), and deliver (total_delivered, delivery_latency). get_metrics_summary() shows real-time event statistics. All metrics operations use file locking and atomic writes. Errors don't fail main operations.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create test script demonstrating event metrics</name>
  <files>.aether/utils/test-event-metrics.sh</files>
  <action>
Create .aether/utils/test-event-metrics.sh with comprehensive metrics tests:

```bash
#!/bin/bash
# Test script for event metrics tracking
# Usage: .aether/utils/test-event-metrics.sh

SCRIPT_DIR="$(dirname "${BASH_SOURCE[0]}")"
source "${SCRIPT_DIR}/event-bus.sh"

echo "=== Event Metrics Test Suite ==="
echo

# Initialize event bus
echo "1. Initializing event bus..."
initialize_event_bus
echo "✓ Event bus initialized"
echo

# Test 1: Initial metrics
echo "2. Testing initial metrics..."
initial_metrics=$(get_event_metrics)
initial_published=$(echo "$initial_metrics" | jq -r '.total_published')
initial_subscriptions=$(echo "$initial_metrics" | jq -r '.total_subscriptions')
echo "Initial - Published: $initial_published, Subscriptions: $initial_subscriptions"
if [ "$initial_published" -eq 0 ] && [ "$initial_subscriptions" -eq 0 ]; then
    echo "✓ Initial metrics correct"
else
    echo "⚠ Initial metrics unexpected (expected 0, 0)"
fi
echo

# Test 2: Publish metrics update
echo "3. Testing publish metrics..."
publish_event "test" "test_event" '{"i": 1}' "pub1" > /dev/null
publish_event "test" "test_event" '{"i": 2}' "pub2" > /dev/null
publish_event "test" "test_event" '{"i": 3}' "pub3" > /dev/null

after_publish=$(get_event_metrics)
after_published=$(echo "$after_publish" | jq -r '.total_published')
publish_rate=$(echo "$after_publish" | jq -r '.publish_rate_per_minute')
echo "After publish - Published: $after_published, Rate: $publish_rate/min"
if [ "$after_published" -ge 3 ] && [ "$publish_rate" -ge 3 ]; then
    echo "✓ Publish metrics updated correctly"
else
    echo "✗ Publish metrics not updated correctly"
    exit 1
fi
echo

# Test 3: Subscription metrics update
echo "4. Testing subscription metrics..."
subscribe_to_events "sub1" "watcher" "test.*" '{}' > /dev/null
subscribe_to_events "sub2" "architect" "test.*" '{}' > /dev/null

after_subscribe=$(get_event_metrics)
after_subscriptions=$(echo "$after_subscribe" | jq -r '.total_subscriptions')
total_subscribers=$(echo "$after_subscribe" | jq -r '.total_subscribers')
echo "After subscribe - Subscriptions: $after_subscriptions, Subscribers: $total_subscribers"
if [ "$after_subscriptions" -ge 2 ] && [ "$total_subscribers" -eq 2 ]; then
    echo "✓ Subscription metrics updated correctly"
else
    echo "✗ Subscription metrics not updated correctly"
    exit 1
fi
echo

# Test 4: Delivery metrics update
echo "5. Testing delivery metrics..."
events=$(get_events_for_subscriber "sub1" "watcher")
event_count=$(echo "$events" | jq 'length')
mark_events_delivered "sub1" "watcher" "$events" > /dev/null

after_deliver=$(get_event_metrics)
after_delivered=$(echo "$after_deliver" | jq -r '.total_delivered')
backlog=$(echo "$after_deliver" | jq -r '.backlog_count')
echo "After delivery - Delivered: $after_delivered, Backlog: $backlog"
if [ "$after_delivered" -ge "$event_count" ]; then
    echo "✓ Delivery metrics updated correctly"
else
    echo "✗ Delivery metrics not updated correctly"
    exit 1
fi
echo

# Test 5: Publish rate calculation (sliding window)
echo "6. Testing publish rate calculation..."
sleep 2  # Wait 2 seconds
# Publish more events
for i in {1..5}; do
    publish_event "rate_test" "rate_event" "{\"i\": $i}" "rate_tester" > /dev/null
done

final_metrics=$(get_event_metrics)
final_rate=$(echo "$final_metrics" | jq -r '.publish_rate_per_minute')
echo "Final publish rate: $final_rate/min (last 60 seconds)"
if [ "$final_rate" -ge 5 ]; then
    echo "✓ Publish rate calculated correctly"
else
    echo "⚠ Publish rate lower than expected (published 5 events)"
fi
echo

# Test 6: Metrics summary output
echo "7. Testing metrics summary..."
echo "Metrics Summary:"
get_metrics_summary
echo "✓ Metrics summary displayed"
echo

# Test 7: Backlog tracking
echo "8. Testing backlog tracking..."
# Publish events without delivering
publish_event "backlog_test" "backlog_event" '{"i": 1}' "pub" > /dev/null
publish_event "backlog_test" "backlog_event" '{"i": 2}' "pub" > /dev/null

backlog_metrics=$(get_event_metrics)
backlog_count=$(echo "$backlog_metrics" | jq -r '.backlog_count')
echo "Current backlog: $backlog_count events"
if [ "$backlog_count" -ge 2 ]; then
    echo "✓ Backlog tracking works correctly"
else
    echo "⚠ Backlog count unexpected (expected >= 2)"
fi
echo

# Test 8: Last updated timestamp
echo "9. Testing last updated timestamp..."
last_updated=$(echo "$final_metrics" | jq -r '.last_updated')
if [ "$last_updated" != "null" ] && [ -n "$last_updated" ]; then
    echo "✓ Last updated timestamp present: $last_updated"
else
    echo "✗ Last updated timestamp missing"
    exit 1
fi
echo

# Test 9: Metrics persistence
echo "10. Testing metrics persistence..."
# Read metrics directly from file
file_metrics=$(jq '.metrics' .aether/data/events.json)
file_published=$(echo "$file_metrics" | jq -r '.total_published')
api_published=$(echo "$final_metrics" | jq -r '.total_published')
if [ "$file_published" -eq "$api_published" ]; then
    echo "✓ Metrics persist correctly (file: $file_published, api: $api_published)"
else
    echo "✗ Metrics mismatch (file: $file_published, api: $api_published)"
    exit 1
fi
echo

echo "=== All Event Metrics Tests Passed ==="
```

Make executable: chmod +x .aether/utils/test-event-metrics.sh

Test script covers:
- Initial metrics (zeros)
- Publish metrics update (total_published, publish_rate)
- Subscription metrics update (total_subscriptions, total_subscribers)
- Delivery metrics update (total_delivered, backlog)
- Publish rate calculation (sliding window over last 60 seconds)
- Metrics summary output (human-readable)
- Backlog tracking (undelivered events)
- Last updated timestamp
- Metrics persistence (file vs API)
  </action>
  <verify>
# Run test script
.aether/utils/test-event-metrics.sh

# Expected output: All tests pass with ✓ checkmarks
# Verify metrics in file
jq '.metrics' .aether/data/events.json
  </verify>
  <done>
test-event-metrics.sh created with comprehensive test coverage. All tests pass: initial metrics, publish metrics, subscription metrics, delivery metrics, publish rate calculation, metrics summary, backlog tracking, last updated timestamp, metrics persistence. Test script demonstrates metrics tracking works correctly with real-time calculations.
  </done>
</task>

</tasks>

<verification>
# Overall verification criteria

1. Metrics tracking works:
   - total_published incremented on each publish
   - total_subscriptions incremented on each subscribe
   - total_delivered incremented on each mark_events_delivered
   - backlog_count reflects undelivered events

2. Publish rate calculated:
   - publish_rate_per_minute counts events in last 60 seconds
   - Sliding window calculation (not cumulative)
   - Updated on each publish operation

3. Delivery latency tracked:
   - average_delivery_latency_ms calculated (placeholder approximation)
   - Would need per-event delivery timestamps for accurate calculation

4. Metrics summary works:
   - get_metrics_summary() displays human-readable metrics
   - Shows all key metrics in formatted output

5. Metrics persist:
   - Metrics stored in events.json metrics section
   - Survive restarts (file-based storage)
   - Accessible via get_event_metrics() API

6. Integration works:
   - event-metrics.sh sourced in event-bus.sh
   - Metrics updated automatically on publish/subscribe/deliver
   - Errors don't fail main operations

7. Safety patterns:
   - File locking prevents concurrent corruption
   - Atomic writes prevent partial corruption
   - Input validation (events.json exists)
</verification>

<success_criteria>
1. event-metrics.sh created with metrics functions
2. calculate_publish_rate() returns events in last 60 seconds
3. get_event_metrics() returns metrics JSON
4. get_metrics_summary() displays human-readable output
5. Metrics updated on publish (total_published, publish_rate)
6. Metrics updated on subscribe (total_subscriptions)
7. Metrics updated on delivery (total_delivered, backlog)
8. event-metrics.sh integrated into event-bus.sh
9. Test script (test-event-metrics.sh) passes all tests
10. Metrics persist in events.json and accessible via API
</success_criteria>

<output>
After completion, create `.planning/phases/09-stigmergic-events/09-07-SUMMARY.md` with:
- Event metrics functions documentation
- Metrics tracked (total_published, publish_rate, subscriptions, delivered, latency, backlog)
- Publish rate calculation (sliding window over last 60 seconds)
- Delivery latency calculation (placeholder approximation)
- Integration with event-bus.sh operations
- Safety patterns used (file locking, atomic writes)
- Test results demonstrating metrics tracking
</output>

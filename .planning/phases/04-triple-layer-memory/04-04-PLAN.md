---
phase: 04-triple-layer-memory
plan: 04
type: execute
wave: 4
depends_on: ["04-03"]
files_modified:
  - .aether/utils/memory-compress.sh
  - .aether/data/memory.json
  - .aether/data/pheromones.json
  - .aether/workers/architect-ant.md
autonomous: true
must_haves:
  truths:
    - "Phase boundary compression trigger works (function prepares data for Architect Ant)"
    - "Architect Ant reads Working Memory and produces compressed session via LLM prompt"
    - "Pattern extraction trigger moves high-value items to Long-term"
    - "Compression and extraction update metrics correctly"
  artifacts:
    - path: ".aether/utils/memory-compress.sh"
      provides: "Compression trigger functions (data preparation)"
      exports: ["trigger_phase_boundary_compression", "trigger_pattern_extraction", "prepare_compression_data"]
    - path: ".aether/workers/architect-ant.md"
      provides: "DAST compression workflow (LLM task)"
      contains: "Compression instruction steps for Architect"
    - path: ".aether/data/pheromones.json"
      provides: "Pheromone signals for compression triggers"
      contains: "phase_complete or token_threshold signals"
  key_links:
    - from: ".aether/utils/memory-compress.sh"
      to: ".aether/workers/architect-ant.md"
      via: "prepare_compression_data creates file for Architect to read"
      pattern: "prepare_compression_data.*working_memory.*json"
    - from: ".aether/workers/architect-ant.md"
      to: ".aether/utils/memory-compress.sh"
      via: "Architect produces compressed JSON, then calls create_short_term_session"
      pattern: "create_short_term_session.*compressed_json"
    - from: ".aether/utils/memory-compress.sh"
      to: ".aether/data/pheromones.json"
      via: "read pheromones to detect phase boundary"
      pattern: "jq.*pheromones.json|phase_complete"
    - from: ".aether/utils/memory-compress.sh"
      to: ".aether/data/COLONY_STATE.json"
      via: "read colony state to determine current phase"
      pattern: "jq.*COLONY_STATE.json|current_phase"
---

<objective>
Implement phase boundary compression trigger (data preparation) and pattern extraction trigger. Architect Ant uses DAST prompt to compress, bash functions handle data preparation and result processing.

Purpose: Compression happens automatically at phase boundaries. bash functions prepare Working Memory data → Architect Ant (LLM) compresses → bash functions process result into Short-term session
Output: Data preparation functions, clarified Architect Ant workflow, wiring documentation for who calls what and when
</objective>

<execution_context>
@~/.claude/cosmic-dev-system/workflows/execute-plan.md
@~/.claude/cosmic-dev-system/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-triple-layer-memory/04-RESEARCH.md

# Key Patterns to Follow
@.aether/workers/architect-ant.md - compression trigger workflow (lines 94-99)
@.aether/utils/memory-compress.sh - compression functions from 04-02, 04-03
@.aether/utils/memory-ops.sh - Working Memory from 04-01
@.aether/data/memory.json - all three memory layers
@.aether/data/pheromones.json - phase completion signals
@.aether/data/COLONY_STATE.json - phase tracking
</context>

<tasks>

<task type="auto">
  <name>Clarify Architect Ant compression workflow</name>
  <files>.aether/workers/architect-ant.md</files>
  <action>
Update architect-ant.md to clarify the compression workflow and who does what:

Add a new section after the "Architect Ant Responsibilities" section:

## Compression Workflow: Phase Boundary

When a phase completes, compression happens in this sequence:

**Step 1: Detect phase boundary**
- bash: `prepare_compression_data()` reads pheromones.json for phase_complete signal
- bash: Check Working Memory has items to compress
- bash: Create temporary file with Working Memory items

**Step 2: Architect Ant compresses (LLM task)**
- Architect: Read temporary file with Working Memory items
- Architect: Apply DAST compression rules (preserve/discard)
- Architect: Produce compressed JSON session
- Architect: Output compressed JSON to stdout or file

**Step 3: Process compressed result**
- bash: `trigger_phase_boundary_compression()` receives compressed JSON from Architect
- bash: Call `create_short_term_session(phase, compressed_json)`
- bash: Call `clear_working_memory()`
- bash: Update metrics

**Important distinction:**
- bash functions: Prepare data, process results, update state files
- Architect Ant (LLM): Apply DAST compression intelligence to produce compressed summary

This section clarifies that the bash function does NOT call the LLM. Instead, it prepares data for the LLM to process, then receives and stores the LLM's output.

Update the "Compress Using DAST" section to reference this workflow.
  </action>
  <verify>
```bash
# Verify workflow documentation exists
grep -A 30 "## Compression Workflow: Phase Boundary" .aether/workers/architect-ant.md

# Verify distinction between bash and LLM responsibilities is documented
grep "bash functions.*Prepare data" .aether/workers/architect-ant.md
grep "Architect Ant.*LLM.*Apply DAST" .aether/workers/architect-ant.md
```
  </verify>
  <done>
Architect Ant documentation clarifies compression workflow: bash prepares data → LLM compresses → bash processes result. No confusion about who calls whom.
  </done>
</task>

<task type="auto">
  <name>Implement compression data preparation function</name>
  <files>.aether/utils/memory-compress.sh</files>
  <action>
Add prepare_compression_data() function to memory-compress.sh:

**prepare_compression_data(phase_number)**
- Check if phase is complete (read pheromones.json for phase_complete signal)
- Get current Working Memory items: `jq '.working_memory.items' .aether/data/memory.json`
- Get current token count
- If Working Memory is empty or below threshold, return 1 (skip compression)
- Create temporary file: `/tmp/working_memory_for_compression_{phase}.json`
- Write Working Memory items to temporary file with metadata:
  ```json
  {
    "phase": phase_number,
    "items": [...working_memory_items],
    "total_tokens": current_tokens,
    "item_count": number_of_items
  }
  ```
- Output file path to stdout (for Architect Ant to read)
- Return 0 (data ready for compression)

This function is called BY the phase boundary orchestrator or BY Architect Ant (if Architect has access to bash). It prepares data for Architect to read and compress.

Reference 04-RESEARCH.md lines 440-492 for compression trigger pattern.
  </action>
  <verify>
```bash
# Source and test
source .aether/utils/memory-compress.sh

# Add test items to Working Memory
source .aether/utils/memory-ops.sh
add_working_memory_item "Decision: Use JSON for state" "decision" 1.0
add_working_memory_item "Outcome: Schema created successfully" "outcome" 0.9

# Test data preparation
prepare_compression_data 1
echo "Preparation result: $?"

# Verify temporary file created
ls -la /tmp/working_memory_for_compression_*.json

# Verify file contents
cat /tmp/working_memory_for_compression_*.json | jq '.items | length'
```
  </verify>
  <done>
prepare_compression_data() creates temporary file with Working Memory items for Architect Ant to read. Returns file path and success status.
  </done>
</task>

<task type="auto">
  <name>Update phase boundary compression trigger</name>
  <files>.aether/utils/memory-compress.sh</files>
  <action>
Update trigger_phase_boundary_compression(phase_number, compressed_json) function in memory-compress.sh:

**trigger_phase_boundary_compression(phase_number, compressed_json)**
- compressed_json is a string argument containing the JSON output from Architect Ant's DAST compression
- Validate compressed_json has required fields: id, session_id, compressed_at, summary, key_decisions, outcomes
- Calculate compression_ratio: original_tokens / compressed_tokens
- Call create_short_term_session(phase_number, compressed_json)
- Call clear_working_memory()
- Increment metrics.total_compressions
- Update metrics.average_compression_ratio
- Return compression summary: items compressed, original tokens, compressed tokens, ratio

This function is called AFTER Architect Ant has produced the compressed JSON. It does NOT invoke Architect Ant.

Usage pattern:
1. Call prepare_compression_data(phase) → creates temp file
2. Architect Ant reads temp file, produces compressed_json
3. Call trigger_phase_boundary_compression(phase, compressed_json) → stores result
  </action>
  <verify>
```bash
# Source and test
source .aether/utils/memory-compress.sh

# Add test items to Working Memory
source .aether/utils/memory-ops.sh
add_working_memory_item "Decision: Use JSON for state" "decision" 1.0
add_working_memory_item "Outcome: Schema created successfully" "outcome" 0.9

# Test with mock compressed output (simulating Architect Ant's output)
compressed_output='{
  "id": "phase_1_test",
  "session_id": "phase_1_test",
  "compressed_at": "2026-02-01T12:00:00Z",
  "original_tokens": 500,
  "compressed_tokens": 200,
  "phase": 1,
  "summary": "Phase 1: Implemented colony state schemas with JSON persistence",
  "key_decisions": [
    {"decision": "Use JSON for state", "rationale": "Human-readable and universal"}
  ],
  "outcomes": [
    {"result": "Schema created", "impact": "Colony state persists across sessions"}
  ],
  "high_value_items": []
}'

# Process compressed output
trigger_phase_boundary_compression 1 "$compressed_output"
echo "Compression result: $?"

# Verify Working Memory cleared
jq '.working_memory.current_tokens' .aether/data/memory.json

# Verify Short-term session created
jq '.short_term_memory.sessions | length' .aether/data/memory.json
jq '.short_term_memory.sessions[-1]' .aether/data/memory.json
```
  </verify>
  <done>
trigger_phase_boundary_compression() receives compressed JSON from Architect Ant, stores it as Short-term session, clears Working Memory, updates metrics.
  </done>
</task>

<task type="auto">
  <name>Document compression trigger wiring</name>
  <files>.aether/utils/memory-compress.sh</files>
  <action>
Add wiring documentation as comments in memory-compress.sh:

Add a file header comment explaining the compression wiring:

```bash
# COMPRESSION TRIGGER WIRING
# ===========================
#
# Who calls what, when:
#
# 1. PHASE BOUNDARY COMPRESSION
#    - Trigger: pheromones.json has phase_complete signal
#    - Caller: Phase boundary orchestrator (future) or manual Queen command
#    - Sequence:
#      a. prepare_compression_data(phase_number)
#         → Creates /tmp/working_memory_for_compression_{phase}.json
#      b. Architect Ant reads temp file, applies DAST compression (LLM task)
#         → Produces compressed_json string
#      c. trigger_phase_boundary_compression(phase_number, compressed_json)
#         → Stores in Short-term, clears Working Memory
#
# 2. TOKEN THRESHOLD COMPRESSION
#    - Trigger: Working Memory reaches 80% capacity (160k tokens)
#    - Caller: auto_compress_if_needed() called during add_working_memory_item
#    - Sequence: Same as phase boundary compression
#
# 3. PATTERN EXTRACTION
#    - Trigger: After Short-term session created, or before eviction
#    - Caller: create_short_term_session() calls trigger_pattern_extraction()
#    - Sequence:
#      a. trigger_pattern_extraction()
#         → Scans Short-term sessions for high-value items
#         → Calls extract_pattern_to_long_term() for repeated patterns
#         → Updates Long-term Memory with associative links
#
# FILES INVOLVED:
# - .aether/utils/memory-compress.sh: This file (bash functions)
# - .aether/workers/architect-ant.md: DAST compression prompt for LLM
# - .aether/data/memory.json: All three memory layers
# - .aether/data/pheromones.json: Phase completion signals
# - .aether/data/COLONY_STATE.json: Current phase tracking
```

Add similar comment blocks before each major function explaining:
- Who calls this function
- When it's called
- What it returns
- What side effects it has
  </action>
  <verify>
```bash
# Verify wiring documentation exists
grep -A 50 "COMPRESSION TRIGGER WIRING" .aether/utils/memory-compress.sh

# Verify function-level documentation exists
grep -A 10 "Who calls:" .aether/utils/memory-compress.sh
```
  </verify>
  <done>
Wiring documentation explains who calls what and when. Each function has header comments explaining its role in the compression workflow.
  </done>
</task>

<task type="auto">
  <name>Implement token threshold compression trigger</name>
  <files>.aether/utils/memory-compress.sh</files>
  <action>
Add check_token_threshold() and auto_compress_if_needed() functions to memory-compress.sh:

**check_token_threshold()**
- Get current_tokens from Working Memory
- Get max_capacity_tokens from Working Memory
- Calculate threshold: max_tokens * 80 / 100
- If current_tokens >= threshold:
  - Return 1 (compression needed)
- Else:
  - Return 0 (no compression needed)

**auto_compress_if_needed()**
- Call check_token_threshold()
- If returns 1:
  - Get current phase from COLONY_STATE.json: `jq '.current_phase'`
  - Call prepare_compression_data(current_phase)
  - Return 1 (compression needed, Architect should compress)
- Else:
  - Return 0 (no compression needed)

Note: This function returns 1 to signal that compression is needed. In practice, the caller must coordinate with Architect Ant to complete the compression.

Reference memory.json compression.triggers section for threshold trigger.
  </action>
  <verify>
```bash
# Source and test
source .aether/utils/memory-compress.sh
source .aether/utils/memory-ops.sh

# Add items until threshold
max=$(jq '.working_memory.max_capacity_tokens' .aether/data/memory.json)
threshold=$((max * 80 / 100))
echo "Threshold: $threshold tokens"

# Check threshold before adding
check_token_threshold
echo "Threshold check result: $?"

# Add large items
add_working_memory_item "$(printf 'A%.0s' {1..50000})" "test" 0.5

# Check threshold after adding
check_token_threshold
echo "Threshold check result: $?"

# Test auto compress trigger
auto_compress_if_needed
echo "Auto compress result: $?"
```
  </verify>
  <done>
Token threshold compression trigger detects when Working Memory exceeds 80% capacity and signals compression is needed. Returns signal code for caller to coordinate with Architect Ant.
  </done>
</task>

<task type="auto">
  <name>Implement pattern extraction trigger</name>
  <files>.aether/utils/memory-compress.sh</files>
  <action>
Add trigger_pattern_extraction() function to memory-compress.sh:

**trigger_pattern_extraction()**
- Get all Short-term sessions
- For each session:
  - Check high_value_items array
  - For items with relevance_score > 0.8:
    - Check if similar pattern exists in Long-term Memory using jq contains()
    - If pattern appears 3+ times across sessions:
      - Call extract_pattern_to_long_term with high confidence
      - Determine pattern_type (success/failure/preference/constraint)
    - Update last_seen timestamp for existing patterns
- Call detect_patterns_across_sessions() to find repeated patterns
- Increment metrics.total_pattern_extractions

Triggers:
1. High relevance (relevance_score > 0.8)
2. Repeated success (appears 3+ times)

This function should be called:
- After create_short_term_session() completes (automatic post-compression)
- Before evict_short_term_session() removes a session (pre-eviction)
- Manually via Queen command

Reference 04-RESEARCH.md lines 99-121, 566-620 for pattern extraction triggers.
Reference architect-ant.md lines 138-146 for pattern extraction workflow.

Update create_short_term_session() to automatically call trigger_pattern_extraction() after creating a session.

Update evict_short_term_session() to automatically call trigger_pattern_extraction() on the session about to be evicted.
  </action>
  <verify>
```bash
# Source and test
source .aether/utils/memory-compress.sh

# Create test sessions with high-value items
session1='{
  "id": "test_1",
  "session_id": "test_1",
  "compressed_at": "2026-02-01T10:00:00Z",
  "original_tokens": 1000,
  "compressed_tokens": 400,
  "phase": 1,
  "summary": "Test session 1",
  "key_decisions": [],
  "outcomes": [],
  "high_value_items": [
    {"content": "Use atomic writes for state files", "relevance_score": 0.9, "type": "preference"}
  ]
}'

session2='{
  "id": "test_2",
  "session_id": "test_2",
  "compressed_at": "2026-02-01T11:00:00Z",
  "original_tokens": 1000,
  "compressed_tokens": 400,
  "phase": 2,
  "summary": "Test session 2",
  "key_decisions": [],
  "outcomes": [],
  "high_value_items": [
    {"content": "Use atomic writes for state files", "relevance_score": 0.9, "type": "preference"}
  ]
}'

# Create sessions (should auto-trigger pattern extraction)
create_short_term_session 1 "$session1"
create_short_term_session 2 "$session2"

# Check for patterns
jq '.long_term_memory.patterns | length' .aether/data/memory.json
jq '.metrics.total_pattern_extractions' .aether/data/memory.json
```
  </verify>
  <done>
Pattern extraction trigger finds high-value items (relevance > 0.8) and repeated patterns (3+ occurrences), moves them to Long-term Memory with appropriate confidence scoring. Automatically called after session creation and before eviction.
  </done>
</task>

</tasks>

<verification>
1. prepare_compression_data() creates temp file with Working Memory items
2. Architect Ant documentation clarifies bash prepares data → LLM compresses → bash processes result
3. trigger_phase_boundary_compression() receives compressed_json and stores it
4. Wiring documentation explains who calls what and when
5. check_token_threshold() detects when at 80% capacity
6. auto_compress_if_needed() signals compression needed
7. trigger_pattern_extraction() extracts high-value items
8. Repeated patterns (3+ occurrences) detected and stored
9. Pattern extraction automatically called after session creation
10. Pattern extraction automatically called before session eviction
11. All function headers document caller/callee relationships
</verification>

<success_criteria>
- Compression workflow clearly documented (bash prepares → LLM compresses → bash processes)
- Data preparation function creates temp file for Architect Ant
- Phase boundary compression receives compressed JSON and stores it
- Token threshold compression trigger detects 80% capacity
- Pattern extraction moves high-value items to Long-term
- Metrics track compressions and pattern extractions
- Wiring documentation explains all trigger relationships
- Functions have header comments explaining their role
</success_criteria>

<output>
After completion, create `.planning/phases/04-triple-layer-memory/04-04-SUMMARY.md` with:
- Compression workflow clarified (bash prepares data, LLM compresses, bash processes result)
- Data preparation function implemented
- Wiring documentation added
- Token threshold trigger implemented
- Pattern extraction trigger implemented
- Automatic pattern extraction integrated with session creation/eviction
- Metrics tracking verified
</output>

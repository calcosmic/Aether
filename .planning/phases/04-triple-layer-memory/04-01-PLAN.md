---
phase: 04-triple-layer-memory
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .aether/data/memory.json
  - .aether/utils/memory-ops.sh
autonomous: true
must_haves:
  truths:
    - "Working Memory stores current session items with metadata (type, timestamp, relevance_score)"
    - "Working Memory read/write/update operations work correctly"
    - "When Working Memory exceeds 160k tokens (80% capacity), oldest items are evicted via LRU policy"
  artifacts:
    - path: ".aether/utils/memory-ops.sh"
      provides: "Working Memory read/write/update functions"
      exports: ["add_working_memory_item", "get_working_memory_item", "update_working_memory_item", "list_working_memory_items"]
    - path: ".aether/data/memory.json"
      provides: "Working Memory storage with item schema"
      contains: "working_memory.items array"
  key_links:
    - from: ".aether/utils/memory-ops.sh"
      to: ".aether/data/memory.json"
      via: "jq operations with atomic-write.sh"
      pattern: "jq.*working_memory.*items"
    - from: ".aether/utils/memory-ops.sh"
      to: ".aether/utils/atomic-write.sh"
      via: "source and function call"
      pattern: "atomic_write_from_file"
---

<objective>
Implement Working Memory read/write/update operations with LRU eviction policy for current session item management.

Purpose: Working Memory is the colony's immediate context storage - items added during current session with metadata for intelligent eviction
Output: Working Memory operations library (.aether/utils/memory-ops.sh) with add, get, update, list functions plus LRU eviction at 80% capacity
</objective>

<execution_context>
@~/.claude/cosmic-dev-system/workflows/execute-plan.md
@~/.claude/cosmic-dev-system/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-triple-layer-memory/04-RESEARCH.md

# Key Patterns to Follow
@.claude/commands/ant/init.md - jq + atomic-write pattern (lines 69-95, 112-139)
@.aether/utils/atomic-write.sh - atomic write functions
@.aether/data/memory.json - existing Working Memory schema
</context>

<tasks>

<task type="auto">
  <name>Create memory-ops.sh with Working Memory functions</name>
  <files>.aether/utils/memory-ops.sh</files>
  <action>
Create .aether/utils/memory-ops.sh with these functions:

1. **add_working_memory_item(content, type, relevance)**
   - Generate item_id: "wm_$(date +%s)_$(md5sum | cut -c1-8)"
   - Estimate tokens: $((${#content} + 3) / 4)  # 4 chars per token heuristic
   - Timestamp: ISO-8601 format
   - Check capacity: if current_tokens + new_tokens > threshold (160k), call evict_lru_working_memory
   - Add item via jq to working_memory.items array with full metadata
   - Update working_memory.current_tokens
   - Use atomic-write.sh for write operation
   - Return item_id

2. **get_working_memory_item(item_id)**
   - Query working_memory.items[] | select(.id == $item_id)
   - Update access_count and last_accessed timestamp
   - Return item as JSON

3. **update_working_memory_item(item_id, updates_json)**
   - Merge updates with existing item
   - Update last_accessed timestamp
   - Use atomic-write.sh

4. **list_working_memory_items([limit])**
   - Return all items (or limited count)
   - Sort by last_accessed descending (most recent first)

Reference init.md lines 112-139 for jq pattern and atomic-write.sh usage.

Follow the exact pattern from init.md for jq operations and atomic writes.
  </action>
  <verify>
```bash
# Source the functions and test
source .aether/utils/memory-ops.sh

# Test add
id=$(add_working_memory_item "Test observation" "observation" 0.8)
echo "Added item: $id"

# Test get
get_working_memory_item "$id"

# Test list
list_working_memory_items

# Verify memory.json updated
jq '.working_memory.items | length' .aether/data/memory.json
jq '.working_memory.current_tokens' .aether/data/memory.json
```
  </verify>
  <done>
Working Memory functions successfully add items with metadata, retrieve by ID, update fields, and list all items. Token counting uses character heuristic, items stored in memory.json with atomic writes.
  </done>
</task>

<task type="auto">
  <name>Implement LRU eviction for Working Memory</name>
  <files>.aether/utils/memory-ops.sh</files>
  <action>
Add evict_lru_working_memory(needed_tokens) function to memory-ops.sh:

1. **evict_lru_working_memory(needed_tokens)**
   - Get current_tokens and max_capacity_tokens from memory.json
   - Calculate threshold: max_tokens * 80 / 100 (evict at 80%, not 100%)
   - If current_tokens < threshold, return 0 (no eviction needed)
   - Loop until available space >= needed_tokens:
     - Sort items by last_accessed ascending (oldest first) via jq sort_by
     - Remove oldest item from working_memory.items array
     - Subtract item's token_count from current_tokens
     - Increment metrics.working_memory_evictions counter
   - Use atomic-write.sh for each update

Reference 04-RESEARCH.md lines 407-437 for LRU eviction pattern.

Eviction happens automatically when add_working_memory_item would exceed 80% threshold.
  </action>
  <verify>
```bash
# Add items until eviction triggers
source .aether/utils/memory-ops.sh

# Add large items to exceed threshold
for i in {1..20}; do
  add_working_memory_item "Large test item $i with enough content to trigger eviction when capacity is reached" "observation" 0.5
done

# Check that LRU eviction occurred
jq '.metrics.working_memory_evictions' .aether/data/memory.json

# Verify current_tokens doesn't exceed 80% of max
max=$(jq '.working_memory.max_capacity_tokens' .aether/data/memory.json)
current=$(jq '.working_memory.current_tokens' .aether/data/memory.json)
threshold=$((max * 80 / 100))
echo "Current: $current, Threshold: $threshold, Max: $max"
```
  </verify>
  <done>
LRU eviction automatically removes oldest items when Working Memory exceeds 80% capacity (160k tokens). Oldest items (by last_accessed) are removed first, freeing space for new items.
  </done>
</task>

<task type="auto">
  <name>Add token_count field to Working Memory items</name>
  <files>.aether/data/memory.json</files>
  <action>
The memory.json schema needs token_count field added to working_memory items for accurate LRU eviction.

Update the item_schema in memory.json working_memory section to include:
- "token_count": 0  # Number of tokens in this item

This field is already used in add_working_memory_item but needs to be in the schema definition.
  </action>
  <verify>
```bash
# Verify schema includes token_count
jq '.working_memory.item_schema | has("token_count")' .aether/data/memory.json
```
  </verify>
  <done>
token_count field is part of Working Memory item schema, used for accurate capacity tracking during LRU eviction.
  </done>
</task>

</tasks>

<verification>
1. Add items to Working Memory via add_working_memory_item
2. Verify items appear in memory.json working_memory.items array
3. Check current_tokens increases appropriately
4. Add items until exceeding 80% capacity (160k tokens)
5. Verify oldest items are evicted automatically
6. Confirm metrics.working_memory_evictions counter increments
7. Test get_working_memory_item updates access_count and last_accessed
8. Test update_working_memory_item merges changes correctly
9. Verify list_working_memory_items returns items sorted by last_accessed
</verification>

<success_criteria>
- Working Memory stores items with full metadata (type, timestamp, relevance_score, access_count, last_accessed)
- Token counting uses character heuristic (4 chars â‰ˆ 1 token) with 95% accuracy
- LRU eviction triggers at 80% capacity (160k tokens), removing oldest items first
- All operations use atomic writes via atomic-write.sh
- Functions can be sourced and called from other scripts
</success_criteria>

<output>
After completion, create `.planning/phases/04-triple-layer-memory/04-01-SUMMARY.md` with:
- Working Memory operations implemented
- LRU eviction tested and verified
- Token counting accuracy notes
</output>

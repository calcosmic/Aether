---
phase: 10-colony-maturity
plan: 04
type: execute
wave: 4
depends_on: ["10-01", "10-02", "10-03"]
files_modified:
  - .planning/phases/10-colony-maturity**---end-to-end-testing,-pattern-extraction,-production-readiness/tests/performance/timing-baseline.test.sh
  - .planning/phases/10-colony-maturity**---end-to-end-testing,-pattern-extraction,-production-readiness/tests/performance/metrics-tracking.sh
  - .planning/phases/10-colony-maturity**---end-to-end-testing,-pattern-extraction,-production-readiness/README.md
autonomous: false
user_setup: []

must_haves:
  truths:
    - "Performance baselines measured for all colony operations"
    - "Metrics tracked: timing, tokens, file I/O, subprocess spawns"
    - "Bottlenecks identified with quantitative data"
    - "Historical metrics allow before/after comparison"
    - "Documentation explains Aether's philosophy and usage"
    - "Examples demonstrate key scenarios (init, pheromones, recovery, memory)"
  artifacts:
    - path: ".planning/phases/10-colony-maturity**---end-to-end-testing,-pattern-extraction,-production-readiness/tests/performance/timing-baseline.test.sh"
      provides: "Performance baseline measurement"
      exports: ["measure_operation_timing", "establish_baseline"]
    - path: ".planning/phases/10-colony-maturity**---end-to-end-testing,-pattern-extraction,-production-readiness/tests/performance/metrics-tracking.sh"
      provides: "Metrics tracking and reporting"
      exports: ["track_metrics", "generate_report", "compare_baselines"]
    - path: ".planning/phases/10-colony-maturity**---end-to-end-testing,-pattern-extraction,-production-readiness/README.md"
      provides: "Comprehensive colony documentation"
      contains: "Quick Start, Architecture, Command Reference, Examples"
  key_links:
    - from: "timing-baseline.test.sh"
      to: ".aether/utils/*.sh"
      via: "time measurement wrapper"
      pattern: "time.*\\..*\\.sh"
    - from: "metrics-tracking.sh"
      to: "tests/performance/results/*.json"
      via: "JSON write"
      pattern: "jq.*results"
    - from: "README.md"
      to: ".aether/commands/*.md"
      via: "documentation links"
      pattern: "\\[.*\\]\\(.*/.*/.*\\.md\\)"
---

<objective>
Performance measurement, metrics tracking, and comprehensive documentation

Purpose: Measure colony operation performance to identify bottlenecks (without arbitrary pass/fail thresholds), track metrics over time for before/after comparison, and create production-ready documentation explaining Aether's philosophy and usage.

Output: Performance baseline tests, metrics tracking infrastructure, and comprehensive README
</objective>

<execution_context>
@~/.claude/cosmic-dev-system/workflows/execute-plan.md
@~/.claude/cosmic-dev-system/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/phases/10-colony-maturity**---end-to-end-testing,-pattern-extraction,-production-readiness/10-RESEARCH.md
@.planning/phases/10-colony-maturity**---end-to-end-testing,-pattern-extraction,-production-readiness/10-CONTEXT.md
@.planning/phases/10-colony-maturity**---end-to-end-testing,-pattern-extraction,-production-readiness/10-01-SUMMARY.md
@.planning/phases/10-colony-maturity**---end-to-end-testing,-pattern-extraction,-production-readiness/10-02-SUMMARY.md
@.planning/phases/10-colony-maturity**---end-to-end-testing,-pattern-extraction,-production-readiness/10-03-SUMMARY.md
@.aether/QUEEN_ANT_ARCHITECTURE.md
@.aether/HANDOFF.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create performance baseline test</name>
  <files>.planning/phases/10-colony-maturity**---end-to-end-testing,-pattern-extraction,-production-readiness/tests/performance/timing-baseline.test.sh</files>
  <action>
Create performance baseline measurement test:

**timing-baseline.test.sh structure:**
```bash
#!/bin/bash
# Performance baseline measurement

set -e

source ../helpers/colony-setup.sh
source ../helpers/cleanup.sh
source ./metrics-tracking.sh

echo "1..8"  # Plan 8 measurements

# Measure: Colony initialization
echo "ok 1 - Colony init: ${duration}s"

# Measure: Pheromone emission
echo "ok 2 - Pheromone emit: ${duration}s"

# Measure: State transition
echo "ok 3 - State transition: ${duration}s"

# Measure: Memory compression
echo "ok 4 - Memory compress: ${duration}s"

# Measure: Spawn decision
echo "ok 5 - Spawn decision: ${duration}s"

# Measure: Vote aggregation
echo "ok 6 - Vote aggregation: ${duration}s"

# Measure: Event publish
echo "ok 7 - Event publish: ${duration}s"

# Measure: Full workflow
echo "ok 8 - Full workflow: ${duration}s"
```

Implementation requirements:
- Source all utility scripts to measure real operation times
- Use bash time builtin with format output (not external time command)
  - Format: `TIMEFORMAT="%R"` (real time in seconds)
  - Capture: `duration=$(time { operation } 2>&1)`
- Track additional metrics via metrics-tracking.sh:
  - Token usage (estimate via 4 chars/token heuristic)
  - File I/O count (ls -l before/after, diff file count)
  - Subprocess spawns (count bash subprocess calls)
  - Memory footprint (measure RSS via ps)
- Measure each operation 3 times, report median
- Output TAP with diagnostic: "ok N - Operation: median_time (min/max)"
- Save results to tests/performance/results/baseline-$(date +%Y%m%d).json
- JSON structure:
  ```json
  {
    "timestamp": "2026-02-02T10:00:00Z",
    "hardware": {
      "cpu": "Apple M[23]",
      "ram": "16GB",
      "disk": "SSD"
    },
    "operations": {
      "colony_init": {
        "median_s": 0.123,
        "min_s": 0.118,
        "max_s": 0.131,
        "file_io_count": 5,
        "subprocess_spawns": 2
      }
    }
  }
  ```
- Detect hardware via system_profiler (macOS) or /proc/cpuinfo (Linux)
- NO PASS/FAIL THRESHOLDS - report only, identify bottlenecks
  </action>
  <verify>Run `bash tests/performance/timing-baseline.test.sh` and verify baseline JSON created with all 8 operations measured</verify>
  <done>Performance baseline test measures timing, file I/O, subprocess spawns for all colony operations</done>
</task>

<task type="auto">
  <name>Task 2: Create metrics tracking infrastructure</name>
  <files>.planning/phases/10-colony-maturity**---end-to-end-testing,-pattern-extraction,-production-readiness/tests/performance/metrics-tracking.sh</files>
  <action>
Create metrics tracking and reporting utility:

**metrics-tracking.sh functions:**

`track_metrics(operation_name, start_time, end_time)`:
- Calculate duration: end - start
- Count file I/O: ls -1 .aether/data | wc -l
- Count subprocess spawns: track via $BASHPID inheritance
- Estimate tokens: find .aether/data -name "*.json" -exec wc -c {} + | awk '{sum+=$1} END {print sum/4}'
- Output JSON to stdout for capture

`generate_report(baseline_file, current_file)`:
- Load both JSON files via jq
- Compare each operation: delta = current - baseline
- Calculate percent change: (delta / baseline) * 100
- Output table:
  ```
  Operation              | Baseline | Current  | Delta    | Change
  -----------------------|----------|----------|----------|--------
  colony_init            | 0.123s   | 0.118s   | -0.005s  | -4.1%
  pheromone_emit         | 0.045s   | 0.047s   | +0.002s  | +4.4%
  ```
- Color code: green for improvement (>5% faster), red for regression (>5% slower)
- Identify bottlenecks (slowest 3 operations)

`compare_baselines(file1, file2)`:
- Compare two historical baselines
- Show trend over time (improvement or degradation)
- Useful for before/after optimization validation

`save_metrics(operation_name, metrics_json)`:
- Append to tests/performance/results/history.jsonl
- JSONL format (one JSON per line) for time-series data
- Structure: `{"timestamp":"...", "operation":"...", "metrics":{...}}`

`plot_metrics(operation_name, output_file)`:
- Optional: Generate simple ASCII plot if gnuplot available
- Show trend over last N runs
- Fallback: table format if no plotting tools

Implementation requirements:
- Use jq for all JSON manipulation
- Use bc for floating-point arithmetic (scale=6)
- Handle missing baseline files gracefully (create if not exists)
- Make executable: chmod +x
- Source in timing-baseline.test.sh
  </action>
  <verify>Run `source metrics-tracking.sh && track_metrics "test" 0 1 && echo "Metrics tracking works"` and verify JSON output</verify>
  <done>Metrics tracking infrastructure measures, saves, and compares performance over time</done>
</task>

<task type="auto">
  <name>Task 3: Create comprehensive colony documentation</name>
  <files>.planning/phases/10-colony-maturity**---end-to-end-testing,-pattern-extraction,-production-readiness/README.md</files>
  <action>
Create production-ready README.md in phase directory:

**README.md structure:**

```markdown
# Aether: Queen Ant Colony - Autonomous Multi-Agent System

## Quick Start

[Installation, basic usage, first colony initialization]

## Architecture

### What Makes Aether Unique
[Queen signals, not commands - Workers spawn Workers - Stigmergic communication]

### Core Components
[Pheromones, Memory, Spawning, Verification, Learning, Events]

### Worker Ant Castes
[Colonizer, Route-setter, Builder, Watcher, Scout, Architect]

## Command Reference

[/ant:init, /ant:focus, /ant:redirect, /ant:feedback, /ant:status, /ant:phase, /ant:memory, /ant:recover]

## Caste Behaviors

[Detailed behavior for each caste, capabilities, spawning patterns]

## Examples

### Example 1: Basic Workflow
[Initialize colony, observe emergence, complete goal]

### Example 2: Pheromone Guidance
[Use FOCUS to guide colony, use REDIRECT to avoid anti-patterns]

### Example 3: Recovery from Checkpoint
[Simulate crash, recover from checkpoint, resume work]

### Example 4: Memory Query
[Search compressed memory, retrieve key information]

## Troubleshooting

[Common issues, solutions, debug commands]

## FAQ

[Philosophy, comparison to other systems, production usage]
```

Implementation requirements:
- Write for TWO audiences: conceptual (philosophy) then practical (examples)
- Explain WHY Aether is different (not just WHAT it does)
- Use ASCII diagrams for architecture visualization
- Include code blocks for all command examples
- Add "Production Readiness Checklist" section:
  - [ ] End-to-end tests passing
  - [ ] Stress tests passing
  - [ ] Performance baselines established
  - [ ] Checkpoint recovery verified
  - [ ] Circuit breakers tested
- Add "Performance Tuning" section:
  - How to measure baselines
  - How to identify bottlenecks
  - How to compare before/after
- Reference QUEEN_ANT_ARCHITECTURE.md for deep dive
- Link to command files in .aether/commands/
- Include "Next Steps" at end (Phase 10 completion actions)
- Keep under 500 lines (comprehensive but concise)
  </action>
  <verify>Review README.md for completeness: all sections present, examples work, links resolve, clarity check</verify>
  <done>README.md provides comprehensive guide to Aether philosophy, architecture, usage, and troubleshooting</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Performance measurement infrastructure, metrics tracking, and comprehensive documentation</what-built>
  <how-to-verify>
1. Run performance baseline test:
   `bash tests/performance/timing-baseline.test.sh`

2. Verify baseline JSON created:
   `cat tests/performance/results/baseline-*.json`
   - Check all 8 operations present
   - Verify hardware info captured
   - Check metrics (timing, file_io, subprocesses)

3. Test metrics tracking:
   ```bash
   source tests/performance/metrics-tracking.sh
   generate_report baseline-20260202.json baseline-20260202.json
   ```
   - Verify table output
   - Check delta calculations (should be 0% for same file)

4. Review README.md:
   - Quick Start section gets user to first colony
   - Architecture explains Aether's uniqueness
   - Command Reference covers all /ant:* commands
   - Examples demonstrate key scenarios
   - Troubleshooting solves common issues
   - FAQ addresses philosophy questions
   - Production Readiness Checklist included
   - Performance Tuning section explains metrics

5. Test examples from README:
   - Run `/ant:init "test goal"` and verify works
   - Run `/ant:focus "test"` and verify guidance
   - Run `/ant:status` and verify readable

Expected:
- Baseline JSON with 8 operations measured
- Metrics tracking generates comparison reports
- README is comprehensive and accurate
- Examples work as documented
  </how-to-verify>
  <resume-signal>Type "approved" if performance tracking works and documentation is complete, or describe issues</resume-signal>
</task>

</tasks>

<verification>
- timing-baseline.test.sh measures all 8 colony operations
- Baseline JSON created with proper structure
- metrics-tracking.sh provides track_metrics, generate_report, compare_baselines functions
- README.md is comprehensive (all sections present)
- README.md examples are accurate and tested
- Documentation explains Aether's philosophy clearly
- Performance section explains measurement approach
</verification>

<success_criteria>
- Performance baselines established for all colony operations
- Metrics tracking enables before/after comparison
- Bottlenecks identified with quantitative data
- Comprehensive documentation explains Aether's uniqueness
- Examples demonstrate key scenarios
- Troubleshooting section solves common issues
- Production readiness checklist included
</success_criteria>

<output>
After completion, create `.planning/phases/10-colony-maturity**---end-to-end-testing,-pattern-extraction,-production-readiness/10-04-SUMMARY.md`
</output>

---
phase: 05-phase-boundaries
plan: 06
type: execute
wave: 3
depends_on: ["05-02", "05-04"]
files_modified:
  - .aether/utils/state-machine.sh
  - .aether/data/COLONY_STATE.json
autonomous: true

must_haves:
  truths:
    - "State history tracked in COLONY_STATE.json state_machine.state_history array"
    - "Each transition logged with from/to/trigger/timestamp/checkpoint"
    - "State history limited to 100 entries (old entries archived)"
    - "Archived history moved to memory system for analysis"
  artifacts:
    - path: ".aether/utils/state-machine.sh"
      provides: "archive_state_history() function"
      exports: ["archive_state_history"]
      contains: "archive_state_history()"
    - path: ".aether/data/COLONY_STATE.json"
      provides: "state_machine.state_history array with entries"
      contains: "state_machine.state_history"
  key_links:
    - from: "transition_state()"
      to: "state_machine.state_history"
      via: "jq appends transition entry to history array"
      pattern: "state_history += \[\{.*from.*to.*trigger.*timestamp.*checkpoint.*\}\]"
    - from: "archive_state_history()"
      to: ".aether/data/memory.json"
      via: "Archived history added to Working Memory"
      pattern: "add_working_memory_item.*state_history_archive"
---

<objective>
Implement state history logging with archival to memory system when history exceeds 100 entries.

Purpose: Track all state transitions for debugging and analysis. Prevent COLONY_STATE.json bloat by archiving old history to memory system.

Output: State history tracking in transition_state(), archive_state_history() function, history archival integration
</objective>

<execution_context>
@~/.claude/cosmic-dev-system/workflows/execute-plan.md
@~/.claude/cosmic-dev-system/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-phase-boundaries/05-RESEARCH.md
@.planning/phases/05-phase-boundaries/05-02-SUMMARY.md
@.aether/utils/state-machine.sh
@.aether/utils/memory-ops.sh
@.aether/data/COLONY_STATE.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add archive_state_history() to state-machine.sh</name>
  <files>.aether/utils/state-machine.sh</files>
  <action>
Add archive_state_history() function to state-machine.sh:

**Function signature:**
```bash
archive_state_history() {
    # ... implementation
}
```

**Implementation:**

1. **Check history length:**
   ```bash
   local history_length=$(jq -r '.state_machine.state_history | length' "$COLONY_STATE")
   local MAX_HISTORY=100
   ```

2. **If history exceeds MAX_HISTORY, archive:**
   ```bash
   if [ "$history_length" -gt "$MAX_HISTORY" ]; then
       # Extract full history
       local full_history=$(jq -r '.state_machine.state_history' "$COLONY_STATE")

       # Create archive entry
       local archive_entry=$(echo "$full_history" | jq -c --arg timestamp "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" '{
         type: "state_history_archive",
         content: .,
         timestamp: $timestamp,
         metadata: {
           source: "state_machine",
           entries: length
         }
       }')

       # Add to Working Memory (if memory-ops.sh exists)
       if [ -f ".aether/utils/memory-ops.sh" ]; then
           source .aether/utils/memory-ops.sh
           echo "$archive_entry" | jq -c '.' | \
               add_working_memory_item "state_history_archive" 0.3
       fi

       # Keep only last 100 entries in state
       jq '.state_machine.state_history = .state_machine.state_history[-100:]' \
          "$COLONY_STATE" > /tmp/state.tmp

       atomic_write_from_file "$COLONY_STATE" /tmp/state.tmp
       rm -f /tmp/state.tmp

       echo "State history archived: $history_length entries -> 100 entries"
   fi
   ```

3. **Return 0** (no-op if history <= 100)

**Important:**
- Source memory-ops.sh if exists (from Phase 4)
- Use add_working_memory_item() to archive
- Set relevance_score to 0.3 (historical data, low priority)
- Keep last 100 entries in state (recent history most relevant)
- Export function: export -f archive_state_history

**Error handling:** If memory operations fail, still trim history to prevent bloat:
```bash
# Trim history even if memory archive fails
jq '.state_machine.state_history = .state_machine.state_history[-100:]' \
   "$COLONY_STATE" > /tmp/state.tmp
atomic_write_from_file "$COLONY_STATE" /tmp/state.tmp
```
  </action>
  <verify>
```bash
# Source dependencies
source .aether/utils/atomic-write.sh
source .aether/utils/state-machine.sh

# Test 1: Function exists
type archive_state_history >/dev/null 2>&1 || { echo "Function not found"; exit 1; }

# Test 2: Run on current state (should be no-op if <100 transitions)
archive_state_history || { echo "archive_state_history failed"; exit 1; }

# Test 3: Verify history still present
history_count=$(jq -r '.state_machine.state_history | length' .aether/data/COLONY_STATE.json)
[ "$history_count" -ge 0 ] || { echo "History corrupted"; exit 1; }

# Test 4: Simulate many transitions (to test archival)
# Note: This would require 101 transitions, which is time-consuming
# For now, verify function exists and runs without error

echo "All archive_state_history tests passed"
```
  </verify>
  <done>
archive_state_history() function exists, trims history to 100 entries, archives old history to Working Memory
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate archival into transition_state()</name>
  <files>.aether/utils/state-machine.sh</files>
  <action>
Update transition_state() function to call archive_state_history():

**Add call after state update and before lock release:**

```bash
# Update state in COLONY_STATE.json
jq --arg current "$current_state" \
   --arg new "$new_state" \
   --arg trigger "$trigger_pheromone" \
   --arg timestamp "$timestamp" \
   --arg checkpoint "$checkpoint_file" \
   '
   .colony_status.state = $new |
   .state_machine.last_transition = $timestamp |
   .state_machine.transitions_count += 1 |
   .state_machine.state_history += [{
     "from": $current,
     "to": $new,
     "trigger": $trigger,
     "timestamp": $timestamp,
     "checkpoint": $checkpoint_file
   }]
   ' "$COLONY_STATE" > /tmp/state_transition.tmp

if ! atomic_write_from_file "$COLONY_STATE" /tmp/state_transition.tmp; then
    echo "Failed to write state transition"
    release_lock
    return 1
fi
rm -f /tmp/state_transition.tmp

# Archive old history if exceeds 100 entries
archive_state_history
```

**Location:** After state update, before post-transition checkpoint

**Behavior:**
- Every transition checks if history exceeds 100 entries
- If yes, old entries archived to memory, recent 100 kept
- History archival happens before checkpoint (checkpoint includes trimmed history)
- Prevents unbounded growth of state_history array

**Note:** archive_state_history() is a no-op if history <= 100, so this has minimal performance impact for normal operation.
  </action>
  <verify>
```bash
# Source dependencies
source .aether/utils/file-lock.sh
source .aether/utils/atomic-write.sh
source .aether/utils/state-machine.sh

# Test 1: Perform transition (should trigger archival check)
transition_state "INIT" "test_archival" || { echo "Transition failed"; exit 1; }

# Test 2: Verify history entry added
history_count=$(jq -r '.state_machine.state_history | length' .aether/data/COLONY_STATE.json)
[ "$history_count" -ge 1 ] || { echo "History not updated"; exit 1; }

# Test 3: Verify latest entry has all required fields
last_entry=$(jq -r '.state_machine.state_history[-1]' .aether/data/COLONY_STATE.json)
echo "$last_entry" | jq -e '.from' >/dev/null || { echo "Missing 'from' field"; exit 1; }
echo "$last_entry" | jq -e '.to' >/dev/null || { echo "Missing 'to' field"; exit 1; }
echo "$last_entry" | jq -e '.trigger' >/dev/null || { echo "Missing 'trigger' field"; exit 1; }
echo "$last_entry" | jq -e '.timestamp' >/dev/null || { echo "Missing 'timestamp' field"; exit 1; }
echo "$last_entry" | jq -e '.checkpoint' >/dev/null || { echo "Missing 'checkpoint' field"; exit 1; }

# Reset
transition_state "IDLE" "test_reset"

echo "All state history tracking tests passed"
```
  </verify>
  <done>
transition_state() logs all transitions to state_history, calls archive_state_history(), history trimmed at 100 entries
  </done>
</task>

</tasks>

<verification>
1. State history array exists in COLONY_STATE.json
2. Each transition adds entry to state_history
3. Entry has from, to, trigger, timestamp, checkpoint fields
4. archive_state_history() function exists
5. History limited to 100 entries (verify with 101+ transitions if possible)
6. Archived history added to Working Memory (if memory system exists)
7. History archival happens before checkpoint (checkpoint includes trimmed state)
8. State history doesn't grow unbounded
</verification>

<success_criteria>
1. archive_state_history() function exists and is exported
2. State history tracking works in transition_state()
3. All transition metadata logged (from/to/trigger/timestamp/checkpoint)
4. History limited to 100 entries
5. Old history archived to memory system
6. COLONY_STATE.json doesn't bloat over time
7. Debugging capability maintained (recent history available)
</success_criteria>

<output>
After completion, create `.planning/phases/05-phase-boundaries/05-06-SUMMARY.md` with:
- State history tracking verified
- Archival mechanism tested
- Memory system integration documented
- Files modified
</output>

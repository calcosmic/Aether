---
phase: 29-colony-intelligence
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - .aether/workers/watcher-ant.md
autonomous: true

must_haves:
  truths:
    - "Watcher evaluates each of 5 dimensions independently BEFORE computing overall score"
    - "Overall score is a weighted calculation: correctness 0.30 + completeness 0.25 + quality 0.20 + safety 0.15 + integration 0.10"
    - "Score anchors prevent inflation: 1-2 is critical failure, 7-8 is good, 9-10 is excellent"
    - "Watcher output includes per-dimension scores with 1-line reasoning for each"
  artifacts:
    - path: ".aether/workers/watcher-ant.md"
      provides: "Multi-dimensional scoring rubric with weighted dimensions and anchors"
      contains: "Correctness.*0.30"
  key_links:
    - from: ".aether/workers/watcher-ant.md"
      to: "build.md Step 5.5"
      via: "Watcher spawned with spec containing rubric"
      pattern: "Scoring Rubric.*Mandatory"
---

<objective>
Replace the watcher's flat quality scoring with a multi-dimensional rubric (INT-05) that produces meaningfully varied scores across code of different quality.

Purpose: A clean implementation and a messy one should NOT both receive 8/10. The rubric forces per-dimension evaluation with chain-of-thought reasoning before computing the overall score, preventing the "everything is 8/10" failure mode.

Output: Updated watcher-ant.md with 5-dimension scoring rubric, weighted calculation, score anchors, and mandatory chain-of-thought requirement.
</objective>

<execution_context>
@~/.claude/cosmic-dev-system/workflows/execute-plan.md
@~/.claude/cosmic-dev-system/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/29-colony-intelligence/29-RESEARCH.md
@.aether/workers/watcher-ant.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add scoring rubric to watcher-ant.md</name>
  <files>.aether/workers/watcher-ant.md</files>
  <action>
Add a new "## Scoring Rubric (Mandatory)" section to watcher-ant.md, placed BEFORE the "## Output Format" section (so it's part of the workflow the watcher follows before producing output).

The rubric section must contain:

**1. Dimension table:**

| Dimension | Weight | Evaluate |
|-----------|--------|----------|
| Correctness (0.30) | Does code run? Syntax valid? Imports resolve? Tests pass? |
| Completeness (0.25) | All task requirements addressed? Success criteria met? |
| Quality (0.20) | Readable? Good naming? Error handling? Single responsibility? |
| Safety (0.15) | No secrets in code? No destructive ops? Input validated? |
| Integration (0.10) | Fits existing patterns? Conventions followed? Backwards compatible? |

**2. Score anchors (CRITICAL for preventing inflation):**

| Score | Meaning | Anchor |
|-------|---------|--------|
| 1-2 | Critical failure | Code doesn't parse, missing files, fundamentally broken |
| 3-4 | Major issues | Code runs but has critical bugs, missing major requirements |
| 5-6 | Functional with issues | Code works but has notable quality problems, incomplete features |
| 7-8 | Good | Code works well, minor issues, most requirements met |
| 9-10 | Excellent | Clean, complete, well-tested, follows all conventions |

**3. Mandatory output format for rubric evaluation:**

```
Scoring Rubric:
  Correctness:  {score}/10 - {1-line reason}
  Completeness: {score}/10 - {1-line reason}
  Quality:      {score}/10 - {1-line reason}
  Safety:       {score}/10 - {1-line reason}
  Integration:  {score}/10 - {1-line reason}

  Overall: {weighted_score}/10
  = round(C*0.30 + Co*0.25 + Q*0.20 + S*0.15 + I*0.10)
```

**4. Chain-of-thought mandate (bold, prominent):**

"IMPORTANT: You MUST evaluate each dimension SEPARATELY and show your reasoning BEFORE computing the overall score. Do NOT decide the overall score first and reverse-engineer dimension scores to match. The per-dimension evaluation IS the process -- the overall score is just the weighted average of your individual assessments."

**5. Integration with existing "Execution Verification" section:**

Add a note after the Execution Verification section: "After completing Execution Verification, proceed to the Scoring Rubric. Your Execution Verification results directly feed the Correctness dimension."

**6. Update the Output Format section:**

Update the existing Output Format template to include the rubric output between "Validation Results" and "Issues Found":

```
Scoring Rubric:
  Correctness:  {score}/10 - {reason}
  Completeness: {score}/10 - {reason}
  Quality:      {score}/10 - {reason}
  Safety:       {score}/10 - {reason}
  Integration:  {score}/10 - {reason}

  Overall: {weighted_score}/10
```

Replace the existing `Quality Score: {"star" repeated} ({score}/10)` line with `Quality Score: {"star" repeated for round(weighted_score/2)} ({weighted_score}/10)` to make clear the displayed score comes from the rubric calculation.

**What NOT to change:**
- Do not modify the existing specialist modes (Security, Performance, Quality, Test Coverage) -- they remain as depth modes
- Do not modify the existing Execution Verification section -- it stays as-is
- Do not change the existing "quality_score CANNOT exceed 6/10 if execution fails" rule -- this still applies as a cap on the Correctness dimension (if execution fails, Correctness cannot exceed 6)
- Keep all pheromone sensitivity, spawn mechanics, and activity log sections unchanged

**Key constraint integration:** The existing rule "If ANY execution check fails, quality_score CANNOT exceed 6/10" should be restated in the rubric as: "If ANY execution verification check fails, your Correctness score CANNOT exceed 6/10. This caps the overall score since Correctness has the highest weight."
  </action>
  <verify>
Read the modified watcher-ant.md and confirm:
1. "## Scoring Rubric (Mandatory)" section exists before "## Output Format"
2. All 5 dimensions listed with correct weights (0.30, 0.25, 0.20, 0.15, 0.10)
3. Score anchors table present (1-2 through 9-10)
4. Chain-of-thought mandate is bold and prominent
5. Output format template includes rubric section
6. Execution Verification -> Correctness dimension link is explicit
7. "Cannot exceed 6/10" rule integrated into rubric context
8. Existing specialist modes, pheromone, spawn, and activity log sections unchanged
  </verify>
  <done>Watcher ant has a mandatory 5-dimension scoring rubric with weighted calculation, score anchors, chain-of-thought requirement, and integration with execution verification.</done>
</task>

</tasks>

<verification>
After task completes:
1. Read the full watcher-ant.md and verify logical flow: Workflow -> Execution Verification -> Scoring Rubric -> Output Format
2. Grep for "0.30" to confirm weight appears in rubric
3. Grep for "BEFORE computing" to confirm chain-of-thought mandate
4. Verify the Output Format section reflects the new rubric output structure
5. Confirm no unintended changes to specialist modes or spawn mechanics
</verification>

<success_criteria>
1. Watcher-ant.md contains a mandatory scoring rubric with 5 weighted dimensions
2. Chain-of-thought evaluation is required before overall score computation
3. Score anchors define what each score range means to prevent inflation
4. Output format includes per-dimension scores with reasoning
5. Existing execution verification cap rule integrated into rubric context
</success_criteria>

<output>
After completion, create `.planning/phases/29-colony-intelligence/29-02-SUMMARY.md`
</output>
